{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/J3HDBx1veaoMeBRfFPKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccasanoval/RLtests/blob/master/stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvRerGfIYRgJ",
        "outputId": "3a808a91-6349-4088-db15-820ca3e74bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Aug 30 11:50:19 2024\n",
        "\n",
        "@author: cesar.casanova\n",
        "\"\"\"\n",
        "\n",
        "#!pip install gym pandas yfinance stable-baselines3 shimmy\n",
        "\n",
        "TRAIN = True\n",
        "\n",
        "TICKER = \"SCYR.MC\"\n",
        "TICKER_TEST = TICKER #\"OHLA.MC\"\n",
        "\n",
        "START = \"2020-01-01\"\n",
        "END = \"2024-08-30\"\n",
        "\n",
        "INITIAL_BALANCE = 2000\n",
        "TRAIN_STEPS = 100_000\n",
        "\n",
        "MODEL_NAME = f\"stock_{TICKER}_{int(TRAIN_STEPS/1000)}k\"\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# TRAIN ENVIRONMENT\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "class StockTradingEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df, pct_df, max_steps=1000):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        self.pct_df = pct_df\n",
        "        self.reward_range = (-np.inf, np.inf)\n",
        "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float16)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(5, 5), dtype=np.float16)\n",
        "        self.initial_balance = INITIAL_BALANCE\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.current_step = 6\n",
        "        self.max_steps=max_steps\n",
        "        self.train_cnt_epoch=len(self.df.loc[:, 'Close'].values) -2 -6\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      self.current_step += 1\n",
        "\n",
        "      action_type = action[0]\n",
        "      amount = action[1]\n",
        "\n",
        "      close_price = self.df.loc[self.current_step, 'Close']\n",
        "      next_day_close_price=self.df.loc[self.current_step+1, 'Close']\n",
        "\n",
        "      shares_bought = 0\n",
        "      shares_sold = 0\n",
        "      asset_value_before_action = self.balance + self.shares_held * close_price\n",
        "\n",
        "      if action_type < 1:\n",
        "          # Hold\n",
        "          pass\n",
        "      elif action_type < 2:\n",
        "          # Buy\n",
        "          total_possible = int(self.balance / close_price)\n",
        "          shares_bought = int(total_possible * amount)\n",
        "          total_cost = shares_bought * close_price\n",
        "          self.balance -= total_cost\n",
        "          self.shares_held += shares_bought\n",
        "      elif action_type < 3:\n",
        "          # Sell\n",
        "          shares_sold = int(self.shares_held * amount)\n",
        "          self.balance += shares_sold * close_price\n",
        "          self.shares_held -= shares_sold\n",
        "\n",
        "      if self.current_step >= self.train_cnt_epoch:\n",
        "          self.current_step = 6\n",
        "\n",
        "      obs = self._next_observation()\n",
        "\n",
        "      asset_value_after_action = self.balance + self.shares_held * next_day_close_price\n",
        "      reward = asset_value_after_action - asset_value_before_action\n",
        "      done = self.current_step >= self.max_steps or self.balance <= 0\n",
        "\n",
        "      return obs, reward, done, done, {}\n",
        "\n",
        "\n",
        "    def reset(self, seed=0):\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.current_step = 6\n",
        "        obs = self._next_observation()\n",
        "        return obs, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        end_slice = self.current_step + 1\n",
        "        start_slice = end_slice-4\n",
        "        # in iloc the last index is not inclusive; thus we are doing end_slice+1.\n",
        "        obs = self.pct_df.iloc[start_slice:end_slice+1].values\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.df.loc[self.current_step, 'Open']\n",
        "\n",
        "    def close(self):\n",
        "        return\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# TRAIN\n",
        "if TRAIN:\n",
        "    df = yf.download(TICKER, start=START, end=END)\n",
        "    df = df.sort_values('Date')\n",
        "    df = df.drop(columns='Adj Close')\n",
        "    df = df.reset_index(drop=True)\n",
        "    pct_df = df.copy()\n",
        "\n",
        "    for feature in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "        pct_df[feature] = pct_df[feature].pct_change()\n",
        "\n",
        "    print(\"df: \", df.tail(20))\n",
        "    print(\"pct_df: \", pct_df.tail(20))\n",
        "\n",
        "    env = DummyVecEnv([lambda: StockTradingEnv(df, pct_df)])\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "    model.learn(total_timesteps=TRAIN_STEPS)\n",
        "    model.save(MODEL_NAME)\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"--------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kmN1xhiGYT4k",
        "outputId": "ef67d7ca-6b7c-4b4e-d8c8-0a51df378ed1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df:         Open   High    Low  Close   Volume\n",
            "1175  3.114  3.142  3.082  3.114  1601368\n",
            "1176  3.036  3.036  2.954  2.994  2907997\n",
            "1177  3.020  3.060  2.994  3.016  2027933\n",
            "1178  3.054  3.092  3.002  3.080  1529444\n",
            "1179  3.076  3.076  3.018  3.052  1157258\n",
            "1180  3.100  3.100  3.056  3.064   876458\n",
            "1181  3.080  3.100  3.076  3.090  1109798\n",
            "1182  3.110  3.118  3.076  3.112  1008883\n",
            "1183  3.124  3.130  3.092  3.108  2806085\n",
            "1184  3.110  3.138  3.098  3.120  9026136\n",
            "1185  3.140  3.146  3.118  3.134  3961012\n",
            "1186  3.130  3.174  3.126  3.170  3568912\n",
            "1187  3.182  3.182  3.128  3.128  1233998\n",
            "1188  3.140  3.140  3.116  3.124   788793\n",
            "1189  3.126  3.158  3.124  3.148   933400\n",
            "1190  3.150  3.170  3.138  3.158   938280\n",
            "1191  3.166  3.218  3.156  3.202  1784929\n",
            "1192  3.204  3.220  3.186  3.220  1575888\n",
            "1193  3.224  3.244  3.222  3.234  1497706\n",
            "1194  3.226  3.248  3.212  3.234  3781519\n",
            "pct_df:            Open      High       Low     Close    Volume\n",
            "1175 -0.040074 -0.031443 -0.015964 -0.007015 -0.107594\n",
            "1176 -0.025048 -0.033736 -0.041531 -0.038536  0.815945\n",
            "1177 -0.005270  0.007905  0.013541  0.007348 -0.302636\n",
            "1178  0.011258  0.010458  0.002672  0.021220 -0.245811\n",
            "1179  0.007204 -0.005175  0.005330 -0.009091 -0.243347\n",
            "1180  0.007802  0.007802  0.012591  0.003932 -0.242643\n",
            "1181 -0.006452  0.000000  0.006544  0.008486  0.266231\n",
            "1182  0.009740  0.005806  0.000000  0.007120 -0.090931\n",
            "1183  0.004502  0.003849  0.005202 -0.001285  1.781378\n",
            "1184 -0.004481  0.002556  0.001941  0.003861  2.216630\n",
            "1185  0.009646  0.002549  0.006456  0.004487 -0.561162\n",
            "1186 -0.003185  0.008900  0.002566  0.011487 -0.098990\n",
            "1187  0.016613  0.002520  0.000640 -0.013249 -0.654237\n",
            "1188 -0.013199 -0.013199 -0.003836 -0.001279 -0.360783\n",
            "1189 -0.004459  0.005732  0.002567  0.007682  0.183327\n",
            "1190  0.007678  0.003800  0.004481  0.003177  0.005228\n",
            "1191  0.005079  0.015142  0.005736  0.013933  0.902342\n",
            "1192  0.012003  0.000622  0.009506  0.005622 -0.117114\n",
            "1193  0.006242  0.007453  0.011299  0.004348 -0.049611\n",
            "1194  0.000620  0.001233 -0.003104  0.000000  1.524874\n",
            "Using cuda device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 596  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 442         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004492043 |\n",
            "|    clip_fraction        | 0.0242      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.82       |\n",
            "|    explained_variance   | 5.01e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.15e+04    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0034     |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 1.36e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 459         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003100413 |\n",
            "|    clip_fraction        | 0.0142      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.81       |\n",
            "|    explained_variance   | 0.000287    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.29e+03    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    std                  | 0.983       |\n",
            "|    value_loss           | 1.35e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033167992 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.000566     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.78e+03     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    std                  | 0.978        |\n",
            "|    value_loss           | 1.04e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038863504 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.79        |\n",
            "|    explained_variance   | 0.00128      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.02e+03     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00397     |\n",
            "|    std                  | 0.977        |\n",
            "|    value_loss           | 1.52e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033763528 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.79        |\n",
            "|    explained_variance   | 0.00292      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.18e+03     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00368     |\n",
            "|    std                  | 0.977        |\n",
            "|    value_loss           | 1.1e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 465         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004667986 |\n",
            "|    clip_fraction        | 0.0211      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | 0.00305     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.85e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    std                  | 0.973       |\n",
            "|    value_loss           | 1.26e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 462         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004598533 |\n",
            "|    clip_fraction        | 0.0184      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.78       |\n",
            "|    explained_variance   | 0.00312     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.54e+03    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00322    |\n",
            "|    std                  | 0.973       |\n",
            "|    value_loss           | 1.25e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038444423 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.00365      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.58e+03     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    std                  | 0.965        |\n",
            "|    value_loss           | 1.24e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029528518 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.0047       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.69e+03     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    std                  | 0.974        |\n",
            "|    value_loss           | 1.16e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036465407 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.78        |\n",
            "|    explained_variance   | 0.00995      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.67e+03     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    std                  | 0.973        |\n",
            "|    value_loss           | 8.36e+03     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033691945 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.78        |\n",
            "|    explained_variance   | 0.013        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.21e+03     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    std                  | 0.973        |\n",
            "|    value_loss           | 1.21e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 444          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048883464 |\n",
            "|    clip_fraction        | 0.0344       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.00891      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.84e+03     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00362     |\n",
            "|    std                  | 0.985        |\n",
            "|    value_loss           | 1.18e+04     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 438       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 65        |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0038372 |\n",
            "|    clip_fraction        | 0.0177    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.8      |\n",
            "|    explained_variance   | 0.00594   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.45e+03  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -0.00205  |\n",
            "|    std                  | 0.981     |\n",
            "|    value_loss           | 1.15e+04  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057267607 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.00763      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.9e+03      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00489     |\n",
            "|    std                  | 0.981        |\n",
            "|    value_loss           | 1.1e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 75           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027430432 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.0108       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.08e+03     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 1.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037919397 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.0157       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.03e+04     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 1.68e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 437         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005113351 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.8        |\n",
            "|    explained_variance   | 0.0162      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.37e+03    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0038     |\n",
            "|    std                  | 0.98        |\n",
            "|    value_loss           | 1.3e+04     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 440         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 88          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004457807 |\n",
            "|    clip_fraction        | 0.033       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | 0.0151      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.35e+03    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00397    |\n",
            "|    std                  | 0.976       |\n",
            "|    value_loss           | 1.35e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029454087 |\n",
            "|    clip_fraction        | 0.00903      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.79        |\n",
            "|    explained_variance   | 0.0188       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.61e+03     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    std                  | 0.979        |\n",
            "|    value_loss           | 2.1e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036845934 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.0202       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.8e+03      |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00207     |\n",
            "|    std                  | 0.978        |\n",
            "|    value_loss           | 1.41e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 444         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005426462 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | 0.015       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.56e+04    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00486    |\n",
            "|    std                  | 0.975       |\n",
            "|    value_loss           | 2.31e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042139725 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.78        |\n",
            "|    explained_variance   | 0.0193       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.05e+03     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    std                  | 0.971        |\n",
            "|    value_loss           | 1.19e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004480987 |\n",
            "|    clip_fraction        | 0.0244      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.77       |\n",
            "|    explained_variance   | 0.0114      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.53e+03    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    std                  | 0.968       |\n",
            "|    value_loss           | 1.2e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093904575 |\n",
            "|    clip_fraction        | 0.0716       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.0103       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.4e+03      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00767     |\n",
            "|    std                  | 0.961        |\n",
            "|    value_loss           | 1.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 127         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006708552 |\n",
            "|    clip_fraction        | 0.0457      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.75       |\n",
            "|    explained_variance   | 0.00749     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.91e+03    |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00436    |\n",
            "|    std                  | 0.958       |\n",
            "|    value_loss           | 9.29e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 419         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 131         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006082807 |\n",
            "|    clip_fraction        | 0.0409      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.74       |\n",
            "|    explained_variance   | 0.022       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.76e+03    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    std                  | 0.943       |\n",
            "|    value_loss           | 1.54e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 419         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 136         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006054835 |\n",
            "|    clip_fraction        | 0.0457      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.71       |\n",
            "|    explained_variance   | 0.0112      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.13e+03    |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00491    |\n",
            "|    std                  | 0.936       |\n",
            "|    value_loss           | 1.4e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 421          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039601126 |\n",
            "|    clip_fraction        | 0.0277       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.71        |\n",
            "|    explained_variance   | 0.0201       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.11e+03     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    std                  | 0.941        |\n",
            "|    value_loss           | 1.2e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038272026 |\n",
            "|    clip_fraction        | 0.0269       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.73        |\n",
            "|    explained_variance   | 0.0192       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.66e+03     |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    std                  | 0.955        |\n",
            "|    value_loss           | 1.26e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047865086 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0169       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.54e+03     |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00422     |\n",
            "|    std                  | 0.96         |\n",
            "|    value_loss           | 1.35e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 425         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 153         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004868861 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.75       |\n",
            "|    explained_variance   | 0.00831     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.78e+03    |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    std                  | 0.952       |\n",
            "|    value_loss           | 1.21e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031726165 |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0172       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.05e+03     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    std                  | 0.958        |\n",
            "|    value_loss           | 1.46e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004664783 |\n",
            "|    clip_fraction        | 0.034       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.75       |\n",
            "|    explained_variance   | 0.0145      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.04e+03    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    std                  | 0.96        |\n",
            "|    value_loss           | 1.31e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 166          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054231687 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.74        |\n",
            "|    explained_variance   | 0.00681      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.78e+03     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0038      |\n",
            "|    std                  | 0.948        |\n",
            "|    value_loss           | 1.54e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035798696 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0124       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.09e+03     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00199     |\n",
            "|    std                  | 0.959        |\n",
            "|    value_loss           | 1.2e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 175         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004785452 |\n",
            "|    clip_fraction        | 0.0337      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.77       |\n",
            "|    explained_variance   | 0.0178      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.96e+03    |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00418    |\n",
            "|    std                  | 0.971       |\n",
            "|    value_loss           | 8.89e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 179          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029065604 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.78        |\n",
            "|    explained_variance   | 0.0235       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74e+04     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    std                  | 0.969        |\n",
            "|    value_loss           | 2.56e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044770613 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.78        |\n",
            "|    explained_variance   | 0.0196       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.45e+03     |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    std                  | 0.968        |\n",
            "|    value_loss           | 1.29e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 190          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055951327 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.0242       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+04     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00315     |\n",
            "|    std                  | 0.961        |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004188602 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.76       |\n",
            "|    explained_variance   | 0.0146      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.26e+03    |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    std                  | 0.961       |\n",
            "|    value_loss           | 1.23e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 199          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040168827 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0267       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.1e+03      |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00344     |\n",
            "|    std                  | 0.953        |\n",
            "|    value_loss           | 1.17e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 203          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047157286 |\n",
            "|    clip_fraction        | 0.0279       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.73        |\n",
            "|    explained_variance   | 0.0279       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.42e+04     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00507     |\n",
            "|    std                  | 0.945        |\n",
            "|    value_loss           | 2.56e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 207          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031531735 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.73        |\n",
            "|    explained_variance   | 0.0158       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7e+03        |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    std                  | 0.948        |\n",
            "|    value_loss           | 1.64e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 212         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005126358 |\n",
            "|    clip_fraction        | 0.0296      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.73       |\n",
            "|    explained_variance   | 0.0311      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.96e+03    |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.00345    |\n",
            "|    std                  | 0.948       |\n",
            "|    value_loss           | 1.27e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 216          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052433317 |\n",
            "|    clip_fraction        | 0.0324       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0354       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.68e+03     |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00401     |\n",
            "|    std                  | 0.963        |\n",
            "|    value_loss           | 1.23e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 96256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005058929 |\n",
            "|    clip_fraction        | 0.0272      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.77       |\n",
            "|    explained_variance   | 0.0192      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.28e+03    |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    std                  | 0.967       |\n",
            "|    value_loss           | 1.31e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006749197 |\n",
            "|    clip_fraction        | 0.0388      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.77       |\n",
            "|    explained_variance   | 0.0372      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.35e+03    |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00468    |\n",
            "|    std                  | 0.962       |\n",
            "|    value_loss           | 1.3e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 230          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047809742 |\n",
            "|    clip_fraction        | 0.0356       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.75        |\n",
            "|    explained_variance   | 0.0312       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5e+03        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00341     |\n",
            "|    std                  | 0.952        |\n",
            "|    value_loss           | 1.59e+04     |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "------------------------------------------------------------------------\n",
            "--------------------------------\n",
            "action: [[0.        0.8001659]] / reward: [0.]\n",
            "action: [[0.        0.8058857]] / reward: [0.]\n",
            "action: [[0.         0.44562557]] / reward: [0.]\n",
            "action: [[0.8111469 0.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.22652715 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.        0.7538062]] / reward: [0.]\n",
            "action: [[0.51044774 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.20811534 0.6169798 ]] / reward: [0.]\n",
            "action: [[0.62386376 0.        ]] / reward: [0.]\n",
            "action: [[0.         0.31393552]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.2714938 0.       ]] / reward: [0.]\n",
            "action: [[1.548624   0.66399264]] / reward: [462.88992]\n",
            "action: [[0.         0.02252748]] / reward: [771.46014]\n",
            "action: [[0. 0.]] / reward: [2417.2224]\n",
            "action: [[0. 0.]] / reward: [462.88364]\n",
            "action: [[0.10185656 0.24265513]] / reward: [-977.1883]\n",
            "action: [[0. 0.]] / reward: [-257.1366]\n",
            "action: [[0. 0.]] / reward: [-205.72816]\n",
            "action: [[0. 0.]] / reward: [-514.2984]\n",
            "action: [[0. 1.]] / reward: [-668.6118]\n",
            "action: [[1.0590065 0.       ]] / reward: [-154.28825]\n",
            "action: [[0.3576081 0.       ]] / reward: [-977.1946]\n",
            "action: [[0.6777774 0.       ]] / reward: [-3497.253]\n",
            "action: [[0.58428335 0.65241843]] / reward: [-1902.943]\n",
            "action: [[1.1711679 0.6258856]] / reward: [897.7483]\n",
            "action: [[0. 0.]] / reward: [-2486.1157]\n",
            "action: [[0. 0.]] / reward: [1657.4386]\n",
            "action: [[0.78744113 1.        ]] / reward: [-3936.349]\n",
            "action: [[0.47152102 0.        ]] / reward: [1450.225]\n",
            "action: [[0.42676675 0.        ]] / reward: [-207.17139]\n",
            "action: [[0. 1.]] / reward: [-1519.2963]\n",
            "action: [[0.         0.46861178]] / reward: [-3176.6926]\n",
            "action: [[0.        0.9498797]] / reward: [-8459.689]\n",
            "action: [[0. 0.]] / reward: [-2762.3584]\n",
            "action: [[0.8413954  0.85433733]] / reward: [-2762.3203]\n",
            "action: [[0. 0.]] / reward: [-12568.691]\n",
            "action: [[0. 0.]] / reward: [-656.06244]\n",
            "action: [[0.         0.04398364]] / reward: [-8183.451]\n",
            "action: [[1.3433093 0.       ]] / reward: [2313.4673]\n",
            "action: [[1.1798846 1.       ]] / reward: [-3634.33]\n",
            "action: [[0.       0.540546]] / reward: [-134.59628]\n",
            "action: [[0. 0.]] / reward: [-493.5581]\n",
            "action: [[0.        0.7065555]] / reward: [-852.5035]\n",
            "action: [[0. 1.]] / reward: [3230.525]\n",
            "action: [[0.5618054  0.02032518]] / reward: [1525.5068]\n",
            "action: [[0.         0.36780155]] / reward: [3409.9756]\n",
            "action: [[0.74369264 0.        ]] / reward: [358.95087]\n",
            "action: [[0.07412826 0.        ]] / reward: [-493.55264]\n",
            "action: [[0.2728411 0.6418722]] / reward: [4980.386]\n",
            "action: [[0.06015891 1.        ]] / reward: [-1794.7158]\n",
            "action: [[0. 1.]] / reward: [1794.7158]\n",
            "action: [[0. 0.]] / reward: [-1660.1141]\n",
            "action: [[0.24659455 0.        ]] / reward: [1346.0562]\n",
            "action: [[0.3375977  0.17672743]] / reward: [3095.8792]\n",
            "action: [[0.7493439 0.9869683]] / reward: [-852.4596]\n",
            "action: [[0.         0.01262119]] / reward: [3230.4753]\n",
            "action: [[0. 1.]] / reward: [5653.4336]\n",
            "action: [[0. 0.]] / reward: [-1749.8615]\n",
            "action: [[0.6716877 0.       ]] / reward: [1166.5615]\n",
            "action: [[1.1416626 0.       ]] / reward: [807.6051]\n",
            "action: [[0. 0.]] / reward: [-2602.321]\n",
            "action: [[0.        0.6895512]] / reward: [-1794.7598]\n",
            "action: [[0.         0.20764445]] / reward: [-314.0525]\n",
            "action: [[0. 0.]] / reward: [1525.5068]\n",
            "action: [[0. 1.]] / reward: [-1256.3088]\n",
            "action: [[1.5747991 0.       ]] / reward: [2063.9194]\n",
            "action: [[0. 0.]] / reward: [1525.5563]\n",
            "action: [[0. 0.]] / reward: [4307.3335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action: [[0.17814606 0.        ]] / reward: [-493.55264]\n",
            "action: [[0. 0.]] / reward: [-1435.765]\n",
            "action: [[1.3536162  0.57395154]] / reward: [-134.60178]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.723994 1.      ]] / reward: [1031.9597]\n",
            "action: [[0. 0.]] / reward: [-269.20355]\n",
            "action: [[0.         0.41292354]] / reward: [628.1544]\n",
            "action: [[0. 0.]] / reward: [-1256.3088]\n",
            "action: [[0.         0.16494286]] / reward: [-2422.9143]\n",
            "action: [[0.2952187 0.4157586]] / reward: [-1884.4633]\n",
            "action: [[0.5011165 0.       ]] / reward: [-134.60178]\n",
            "action: [[0.        0.2818147]] / reward: [2557.5159]\n",
            "action: [[0. 0.]] / reward: [-807.65454]\n",
            "action: [[0. 0.]] / reward: [-628.1544]\n",
            "action: [[0.         0.70300865]] / reward: [-314.0525]\n",
            "action: [[2.577851   0.41133896]] / reward: [633.8928]\n",
            "action: [[0.7682912 0.       ]] / reward: [1611.1934]\n",
            "action: [[0.58116674 0.        ]] / reward: [1399.8839]\n",
            "action: [[0. 0.]] / reward: [792.39264]\n",
            "action: [[1.2996871 1.       ]] / reward: [1293.1774]\n",
            "action: [[0.98511976 0.        ]] / reward: [-1250.085]\n",
            "action: [[0.42711288 0.8559321 ]] / reward: [3879.5374]\n",
            "action: [[0.         0.01357591]] / reward: [1379.3568]\n",
            "action: [[0.       0.432714]] / reward: [4655.4214]\n",
            "action: [[0. 0.]] / reward: [-732.7919]\n",
            "action: [[0. 1.]] / reward: [2370.7769]\n",
            "action: [[0.5141667 0.       ]] / reward: [948.3276]\n",
            "action: [[0. 1.]] / reward: [-3017.3892]\n",
            "action: [[0. 1.]] / reward: [-1250.0427]\n",
            "action: [[0.02659263 0.2793494 ]] / reward: [-5129.5854]\n",
            "action: [[0.        0.4957279]] / reward: [172.44861]\n",
            "action: [[0.        0.9630604]] / reward: [1120.7288]\n",
            "action: [[0.        0.5571881]] / reward: [5000.2715]\n",
            "action: [[0. 0.]] / reward: [-2155.2832]\n",
            "action: [[0. 0.]] / reward: [-1724.254]\n",
            "action: [[0.        0.5702589]] / reward: [129.31404]\n",
            "action: [[0.6638279 1.       ]] / reward: [-1681.1195]\n",
            "action: [[0.        0.6558454]] / reward: [1594.94]\n",
            "action: [[0.99715006 1.        ]] / reward: [-2974.302]\n",
            "action: [[1.3826584  0.12356018]] / reward: [1293.1826]\n",
            "action: [[0. 1.]] / reward: [-86.226944]\n",
            "action: [[0.         0.46574956]] / reward: [1810.4335]\n",
            "action: [[0. 0.]] / reward: [-1853.5206]\n",
            "action: [[0. 1.]] / reward: [-603.52527]\n",
            "action: [[0.        0.6098272]] / reward: [3620.9146]\n",
            "action: [[0.10747805 0.        ]] / reward: [-862.14813]\n",
            "action: [[0.46544123 0.        ]] / reward: [1034.5492]\n",
            "action: [[0.05709216 0.27764255]] / reward: [-1077.6416]\n",
            "action: [[1.5206292 0.       ]] / reward: [-1120.7288]\n",
            "action: [[0.         0.38737828]] / reward: [-2370.8242]\n",
            "action: [[0. 0.]] / reward: [3276.0173]\n",
            "action: [[0. 0.]] / reward: [1724.254]\n",
            "action: [[0.11688372 1.        ]] / reward: [-86.221664]\n",
            "action: [[0.08658986 0.        ]] / reward: [689.6995]\n",
            "action: [[0.8974684 0.       ]] / reward: [1120.734]\n",
            "action: [[0.84072864 1.        ]] / reward: [-646.5702]\n",
            "action: [[0.17390417 0.        ]] / reward: [-905.2405]\n",
            "action: [[0.50813043 0.        ]] / reward: [1336.2697]\n",
            "action: [[0. 0.]] / reward: [1465.5837]\n",
            "action: [[0. 1.]] / reward: [-431.02924]\n",
            "action: [[0. 0.]] / reward: [-2500.1382]\n",
            "action: [[0.07518601 0.2768404 ]] / reward: [-1982.8346]\n",
            "action: [[0.25826716 0.        ]] / reward: [1120.734]\n",
            "action: [[0.43524238 0.        ]] / reward: [-301.76263]\n",
            "action: [[0. 0.]] / reward: [3448.4658]\n",
            "action: [[0.28496873 0.42547068]] / reward: [-3232.9302]\n",
            "action: [[0.        0.7564786]] / reward: [4224.3447]\n",
            "action: [[0.92862946 1.        ]] / reward: [1034.5546]\n",
            "action: [[0. 0.]] / reward: [-603.47784]\n",
            "action: [[0. 0.]] / reward: [-2284.5972]\n",
            "action: [[1.333326 1.      ]] / reward: [-1810.4335]\n",
            "action: [[0. 0.]] / reward: [1896.6552]\n",
            "action: [[0.18804416 0.        ]] / reward: [2112.1487]\n",
            "action: [[1.0585705 0.8961227]] / reward: [-517.2509]\n",
            "action: [[0.451792   0.05866598]] / reward: [1206.9557]\n",
            "action: [[0.09330648 1.        ]] / reward: [-1508.7183]\n",
            "action: [[0. 0.]] / reward: [-1077.6416]\n",
            "action: [[1.5504221 0.       ]] / reward: [-1120.734]\n",
            "action: [[0.01448417 0.        ]] / reward: [689.7048]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.9092839 1.       ]] / reward: [-646.6124]\n",
            "action: [[0. 0.]] / reward: [2888.0752]\n",
            "action: [[0. 0.]] / reward: [-2974.2546]\n",
            "action: [[0. 0.]] / reward: [-258.62808]\n",
            "action: [[0.         0.52360374]] / reward: [215.49352]\n",
            "action: [[2.2718437 0.       ]] / reward: [-474.1638]\n",
            "action: [[0.         0.47380447]] / reward: [-1206.9557]\n",
            "action: [[0.09662651 0.        ]] / reward: [560.38544]\n",
            "action: [[0.31754452 0.        ]] / reward: [86.226944]\n",
            "action: [[0. 0.]] / reward: [-215.5357]\n",
            "action: [[0.         0.22624308]] / reward: [775.87897]\n",
            "action: [[0. 0.]] / reward: [4353.701]\n",
            "action: [[0. 1.]] / reward: [-3620.9092]\n",
            "action: [[0. 1.]] / reward: [2025.9692]\n",
            "action: [[2.0725527 1.       ]] / reward: [0.]\n",
            "action: [[0.         0.63319314]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.3084341  0.96831685]] / reward: [0.]\n",
            "action: [[0.         0.20162448]] / reward: [0.]\n",
            "action: [[0.73004425 0.3518749 ]] / reward: [0.]\n",
            "action: [[0.71443325 0.9197538 ]] / reward: [0.]\n",
            "action: [[0.75716 0.     ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.74787194]] / reward: [0.]\n",
            "action: [[0.92772037 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0.9997535 0.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[1.5846021 0.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.54768515 0.        ]] / reward: [0.]\n",
            "action: [[0.9413557  0.24137968]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.86309075 0.        ]] / reward: [0.]\n",
            "action: [[0.9151079 0.       ]] / reward: [0.]\n",
            "action: [[1.6114446 0.       ]] / reward: [0.]\n",
            "action: [[0.10854387 1.        ]] / reward: [0.]\n",
            "action: [[0.         0.48468342]] / reward: [0.]\n",
            "action: [[0.46893847 1.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.42231983]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0.         0.08569415]] / reward: [0.]\n",
            "action: [[0.38458914 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.2111759 0.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.48797455]] / reward: [0.]\n",
            "action: [[0.        0.6287327]] / reward: [0.]\n",
            "action: [[1.3119842 0.       ]] / reward: [0.]\n",
            "action: [[0.         0.34318933]] / reward: [0.]\n",
            "action: [[0.60063905 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.12530059 1.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.2668665  0.24690694]] / reward: [0.]\n",
            "action: [[0.         0.75540423]] / reward: [0.]\n",
            "action: [[0.9192602  0.10066755]] / reward: [0.]\n",
            "action: [[0.59823406 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.1230383 0.       ]] / reward: [0.]\n",
            "action: [[0.         0.45034373]] / reward: [0.]\n",
            "action: [[0.30977792 0.        ]] / reward: [0.]\n",
            "action: [[0.         0.91838366]] / reward: [0.]\n",
            "action: [[0.5856608 0.       ]] / reward: [0.]\n",
            "action: [[0.         0.14661355]] / reward: [0.]\n",
            "action: [[0.32688704 0.37209472]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.15222469 0.5375325 ]] / reward: [0.]\n",
            "action: [[0.       0.897347]] / reward: [0.]\n",
            "action: [[0.6892305  0.73479986]] / reward: [0.]\n",
            "action: [[0.        0.8507818]] / reward: [0.]\n",
            "action: [[0.        0.8734681]] / reward: [0.]\n",
            "action: [[0.6949226 1.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.37329417]] / reward: [0.]\n",
            "action: [[0.        0.6216589]] / reward: [0.]\n",
            "action: [[1.4347293  0.88413167]] / reward: [-371.22684]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [890.9762]\n",
            "action: [[0.5738274  0.32459918]] / reward: [-1633.4708]\n",
            "action: [[1.0608482 0.       ]] / reward: [-1113.7577]\n",
            "action: [[0. 0.]] / reward: [37.10906]\n",
            "action: [[0.        0.6004481]] / reward: [2710.1194]\n",
            "action: [[0.3663584 0.       ]] / reward: [-593.97205]\n",
            "action: [[0.43342698 0.        ]] / reward: [-668.2719]\n",
            "action: [[0. 0.]] / reward: [-816.75354]\n",
            "action: [[1.395081 0.      ]] / reward: [2450.2607]\n",
            "action: [[0. 1.]] / reward: [-519.7448]\n",
            "action: [[0. 0.]] / reward: [-742.49457]\n",
            "action: [[0.86749303 0.        ]] / reward: [-3341.2778]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.34366637]] / reward: [-742.49457]\n",
            "action: [[0.        0.4915133]] / reward: [148.52254]\n",
            "action: [[0. 0.]] / reward: [-1485.0255]\n",
            "action: [[0.        0.2167616]] / reward: [-519.7494]\n",
            "action: [[0.18643506 1.        ]] / reward: [-1856.2523]\n",
            "action: [[0.         0.10619726]] / reward: [1113.7577]\n",
            "action: [[0. 0.]] / reward: [-2784.3784]\n",
            "action: [[0.        0.6332614]] / reward: [891.0126]\n",
            "action: [[0.8604447 0.4640348]] / reward: [-37.10906]\n",
            "action: [[0. 0.]] / reward: [890.9762]\n",
            "action: [[1.5585368 1.       ]] / reward: [1617.668]\n",
            "action: [[0.7977787  0.48365766]] / reward: [468.2689]\n",
            "action: [[0.09375024 0.2533275 ]] / reward: [127.70638]\n",
            "action: [[0.3943832 1.       ]] / reward: [85.14974]\n",
            "action: [[0.         0.40511426]] / reward: [2085.8901]\n",
            "action: [[0. 0.]] / reward: [-1191.9506]\n",
            "action: [[0. 1.]] / reward: [85.15495]\n",
            "action: [[1.247904   0.19983554]] / reward: [2000.782]\n",
            "action: [[0. 0.]] / reward: [-808.8314]\n",
            "action: [[1.6482935 0.       ]] / reward: [1404.8066]\n",
            "action: [[0.        0.7349682]] / reward: [-510.86722]\n",
            "action: [[0. 0.]] / reward: [-1277.0586]\n",
            "action: [[1.3307143 1.       ]] / reward: [-1873.0756]\n",
            "action: [[0.65865004 0.        ]] / reward: [2894.7214]\n",
            "action: [[0. 0.]] / reward: [2469.0562]\n",
            "action: [[0.1743468 1.       ]] / reward: [1702.7709]\n",
            "action: [[0. 0.]] / reward: [1702.823]\n",
            "action: [[0.6182676 0.       ]] / reward: [766.2279]\n",
            "action: [[0.6266719 0.       ]] / reward: [-681.125]\n",
            "action: [[0.3385709 0.       ]] / reward: [5108.4116]\n",
            "action: [[0. 0.]] / reward: [-3490.7488]\n",
            "action: [[0. 0.]] / reward: [-1277.0951]\n",
            "action: [[0.88613075 0.24217835]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [-1106.806]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0.2736539 0.       ]] / reward: [2128.4988]\n",
            "action: [[0.03315991 1.        ]] / reward: [-681.13544]\n",
            "action: [[0.04203285 0.        ]] / reward: [-595.9701]\n",
            "action: [[0.        0.6116442]] / reward: [1958.2306]\n",
            "action: [[0.23317079 0.        ]] / reward: [936.5378]\n",
            "action: [[0.         0.17865852]] / reward: [255.41277]\n",
            "action: [[0.1605463  0.24875739]] / reward: [-595.98047]\n",
            "action: [[1.0316166  0.71254873]] / reward: [85.11328]\n",
            "action: [[0.7582728 0.       ]] / reward: [-851.39325]\n",
            "action: [[0. 0.]] / reward: [-1958.1785]\n",
            "action: [[0.07584333 0.45874277]] / reward: [-681.13544]\n",
            "action: [[0.04350074 0.        ]] / reward: [1106.806]\n",
            "action: [[0. 0.]] / reward: [-340.56772]\n",
            "action: [[0.5364356 0.       ]] / reward: [681.125]\n",
            "action: [[0. 1.]] / reward: [1021.69275]\n",
            "action: [[0.18536149 0.        ]] / reward: [851.39325]\n",
            "action: [[0.49356574 0.36046606]] / reward: [1277.0951]\n",
            "action: [[0. 0.]] / reward: [-595.9701]\n",
            "action: [[0. 0.]] / reward: [936.5378]\n",
            "action: [[0.05042164 0.21419972]] / reward: [766.2383]\n",
            "action: [[0.33417773 0.        ]] / reward: [-936.5482]\n",
            "action: [[0.5499966  0.15225375]] / reward: [-1532.5078]\n",
            "action: [[0.2450047 0.       ]] / reward: [-681.0834]\n",
            "action: [[0. 1.]] / reward: [-766.27997]\n",
            "action: [[0.48041895 0.6074809 ]] / reward: [1021.69275]\n",
            "action: [[1.0398461 0.9032352]] / reward: [-1617.6732]\n",
            "action: [[1.0479302  0.15585284]] / reward: [1191.9506]\n",
            "action: [[0. 0.]] / reward: [1447.3633]\n",
            "action: [[0.17482823 0.55031306]] / reward: [-2979.871]\n",
            "action: [[0.14954334 1.        ]] / reward: [510.82553]\n",
            "action: [[0.34723094 0.        ]] / reward: [1787.9623]\n",
            "action: [[0.41511708 0.00786503]] / reward: [170.26823]\n",
            "action: [[0. 0.]] / reward: [1702.7656]\n",
            "action: [[0. 0.]] / reward: [595.98047]\n",
            "action: [[1.4222697 0.       ]] / reward: [3405.5938]\n",
            "action: [[0.03767174 0.        ]] / reward: [-170.26823]\n",
            "action: [[0.         0.90450466]] / reward: [1021.65106]\n",
            "action: [[0. 0.]] / reward: [851.3828]\n",
            "action: [[0.2573049 0.       ]] / reward: [-1617.6211]\n",
            "action: [[1.3181429 0.       ]] / reward: [1106.806]\n",
            "action: [[0. 0.]] / reward: [255.41277]\n",
            "action: [[0. 0.]] / reward: [1702.8177]\n",
            "action: [[0.21060404 0.19315313]] / reward: [681.0834]\n",
            "action: [[0. 0.]] / reward: [-3320.4492]\n",
            "action: [[0.         0.85464525]] / reward: [-425.6706]\n",
            "action: [[0.       0.400531]] / reward: [-851.3828]\n",
            "action: [[0. 1.]] / reward: [681.0834]\n",
            "action: [[0. 0.]] / reward: [-425.6706]\n",
            "action: [[0. 1.]] / reward: [-595.98047]\n",
            "action: [[3. 0.]] / reward: [-1958.2306]\n",
            "action: [[0. 0.]] / reward: [510.86722]\n",
            "action: [[0.         0.38620922]] / reward: [-425.71225]\n",
            "action: [[0.9887724  0.38213167]] / reward: [595.98047]\n",
            "action: [[1.6601429 0.       ]] / reward: [-2213.6433]\n",
            "action: [[0. 1.]] / reward: [170.29948]\n",
            "action: [[0.93550175 0.        ]] / reward: [-595.9701]\n",
            "action: [[0.24410862 0.        ]] / reward: [1617.6211]\n",
            "action: [[0. 0.]] / reward: [85.15495]\n",
            "action: [[0. 0.]] / reward: [766.26953]\n",
            "action: [[0. 1.]] / reward: [681.0834]\n",
            "action: [[0. 0.]] / reward: [-170.25781]\n",
            "action: [[0.17913592 0.        ]] / reward: [170.25781]\n",
            "action: [[0.23097178 0.        ]] / reward: [-510.81512]\n",
            "action: [[0.         0.19713446]] / reward: [-766.2383]\n",
            "action: [[0. 0.]] / reward: [1191.9506]\n",
            "action: [[0.        0.7063902]] / reward: [-936.5378]\n",
            "action: [[0.01775977 1.        ]] / reward: [-2128.4883]\n",
            "action: [[1.4470574 0.       ]] / reward: [1532.5078]\n",
            "action: [[0.4922921 0.       ]] / reward: [-851.4245]\n",
            "action: [[1.1127803 0.       ]] / reward: [-1021.65106]\n",
            "action: [[0. 0.]] / reward: [-340.5573]\n",
            "action: [[0.14325264 0.        ]] / reward: [-1191.9506]\n",
            "action: [[0.02267438 0.        ]] / reward: [-255.41277]\n",
            "action: [[1.1004413 0.9567456]] / reward: [1106.7957]\n",
            "action: [[0. 0.]] / reward: [85.15495]\n",
            "action: [[1.2986029 0.       ]] / reward: [2043.3334]\n",
            "action: [[0.         0.08709335]] / reward: [255.41277]\n",
            "action: [[1.3674281 1.       ]] / reward: [-1447.3633]\n",
            "action: [[0. 0.]] / reward: [-170.25781]\n",
            "action: [[0.58789223 1.        ]] / reward: [-851.43494]\n",
            "action: [[0. 0.]] / reward: [510.86722]\n",
            "action: [[0.         0.85462886]] / reward: [2128.4883]\n",
            "action: [[0. 0.]] / reward: [936.5378]\n",
            "action: [[0.8594999 1.       ]] / reward: [-1617.6628]\n",
            "action: [[1.095758 0.      ]] / reward: [-595.9701]\n",
            "action: [[0.05487552 0.31820828]] / reward: [-1021.69275]\n",
            "action: [[0.85363066 0.        ]] / reward: [0.]\n",
            "action: [[1.9167049 0.       ]] / reward: [0.]\n",
            "action: [[0.         0.04010466]] / reward: [-1702.7761]\n",
            "action: [[0.001545   0.41299915]] / reward: [-851.3828]\n",
            "action: [[0.3586111 0.       ]] / reward: [-1958.2357]\n",
            "action: [[0.38035086 0.07465554]] / reward: [-766.2331]\n",
            "action: [[0.8054198  0.65494823]] / reward: [-4001.569]\n",
            "action: [[0. 0.]] / reward: [212.86133]\n",
            "action: [[0. 0.]] / reward: [2596.7573]\n",
            "action: [[0. 0.]] / reward: [-808.8314]\n",
            "action: [[0.38106185 0.        ]] / reward: [1830.4773]\n",
            "action: [[0. 0.]] / reward: [1787.9259]\n",
            "action: [[1.0527234  0.22738898]] / reward: [-1447.3633]\n",
            "action: [[0.45702085 1.        ]] / reward: [1787.931]\n",
            "action: [[0. 0.]] / reward: [510.86722]\n",
            "action: [[0.         0.02484784]] / reward: [-1532.5183]\n",
            "action: [[0. 0.]] / reward: [851.39325]\n",
            "action: [[0.48616832 0.        ]] / reward: [-510.82553]\n",
            "action: [[0.9139975 1.       ]] / reward: [-255.45964]\n",
            "action: [[0.46032935 0.        ]] / reward: [1617.668]\n",
            "action: [[0.        0.6372934]] / reward: [0.]\n",
            "action: [[0.         0.13298076]] / reward: [-2043.3386]\n",
            "action: [[0.         0.00250778]] / reward: [681.13025]\n",
            "action: [[1.371309 0.      ]] / reward: [1532.4662]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [766.27997]\n",
            "action: [[0.47701383 0.33519763]] / reward: [-1191.9506]\n",
            "action: [[0.3432611 0.       ]] / reward: [-1702.7761]\n",
            "action: [[0. 0.]] / reward: [766.2383]\n",
            "action: [[0. 0.]] / reward: [-1702.7761]\n",
            "action: [[0. 0.]] / reward: [-85.14974]\n",
            "action: [[0. 0.]] / reward: [1362.2084]\n",
            "action: [[0.6386521 0.       ]] / reward: [681.13025]\n",
            "action: [[0. 0.]] / reward: [1021.69275]\n",
            "action: [[0.86327446 0.        ]] / reward: [-170.3099]\n",
            "action: [[0. 1.]] / reward: [766.27997]\n",
            "action: [[0. 1.]] / reward: [-936.5378]\n",
            "action: [[0.         0.22604117]] / reward: [425.6706]\n",
            "action: [[0. 0.]] / reward: [1447.405]\n",
            "action: [[0. 0.]] / reward: [595.98047]\n",
            "action: [[1.0543462 0.       ]] / reward: [-85.15495]\n",
            "action: [[0. 0.]] / reward: [-1447.3633]\n",
            "action: [[0. 0.]] / reward: [2298.746]\n",
            "action: [[1.1029295 0.       ]] / reward: [-766.2279]\n",
            "action: [[0.601895 0.      ]] / reward: [255.41277]\n",
            "action: [[0.        0.8228878]] / reward: [-1191.9506]\n",
            "action: [[1.751148   0.19907156]] / reward: [2469.0457]\n",
            "action: [[0.11242718 0.43131006]] / reward: [-1532.5078]\n",
            "action: [[1.0048962 0.       ]] / reward: [-425.72266]\n",
            "action: [[0. 1.]] / reward: [510.82553]\n",
            "action: [[0.        0.9323772]] / reward: [340.56772]\n",
            "action: [[0.26721448 0.        ]] / reward: [-2043.3439]\n",
            "action: [[0.         0.49348164]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [1617.6732]\n",
            "action: [[0.50158155 0.        ]] / reward: [1362.2084]\n",
            "action: [[0. 0.]] / reward: [-425.6706]\n",
            "action: [[0.8218826 0.       ]] / reward: [1617.6211]\n",
            "action: [[0. 1.]] / reward: [-2469.0562]\n",
            "action: [[1.1129504  0.13705906]] / reward: [255.45444]\n",
            "action: [[0. 0.]] / reward: [-936.5378]\n",
            "action: [[1.595017 0.      ]] / reward: [1021.65106]\n",
            "action: [[0. 1.]] / reward: [-851.39325]\n",
            "action: [[0.6533892  0.41256428]] / reward: [170.3099]\n",
            "action: [[0. 1.]] / reward: [-1617.6628]\n",
            "action: [[0. 0.]] / reward: [3150.129]\n",
            "action: [[0.09791088 0.        ]] / reward: [3831.3062]\n",
            "action: [[0. 1.]] / reward: [766.2383]\n",
            "action: [[1.9021044 0.       ]] / reward: [1787.931]\n",
            "action: [[0.         0.82668424]] / reward: [-681.0834]\n",
            "action: [[1.5319963 0.       ]] / reward: [936.4857]\n",
            "action: [[0.         0.18355906]] / reward: [2128.4988]\n",
            "action: [[0.         0.40236643]] / reward: [-255.41277]\n",
            "action: [[0. 0.]] / reward: [425.71225]\n",
            "action: [[0.41180274 0.        ]] / reward: [681.125]\n",
            "action: [[0. 0.]] / reward: [-2383.9429]\n",
            "action: [[0. 0.]] / reward: [3746.1511]\n",
            "action: [[0. 1.]] / reward: [170.3099]\n",
            "action: [[0. 0.]] / reward: [936.49615]\n",
            "action: [[1.0331035  0.35073102]] / reward: [-681.0834]\n",
            "action: [[0. 0.]] / reward: [170.25781]\n",
            "action: [[0.         0.11131883]] / reward: [766.27997]\n",
            "action: [[0. 1.]] / reward: [1532.4662]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.35406163 0.        ]] / reward: [-510.82553]\n",
            "action: [[0. 1.]] / reward: [-6896.2905]\n",
            "action: [[0.2908734  0.13613877]] / reward: [-1277.0951]\n",
            "action: [[0. 0.]] / reward: [-255.41277]\n",
            "action: [[1.5835483 0.3008636]] / reward: [-1021.69275]\n",
            "action: [[1.8542824 0.       ]] / reward: [-510.82553]\n",
            "action: [[0.9216197 0.       ]] / reward: [-425.6706]\n",
            "action: [[1.5964558  0.90400964]] / reward: [-595.98047]\n",
            "action: [[0.3228382 1.       ]] / reward: [681.0834]\n",
            "action: [[0.291615 0.      ]] / reward: [-1277.0535]\n",
            "action: [[0.47951636 0.6141575 ]] / reward: [-936.5378]\n",
            "action: [[0.         0.77591527]] / reward: [-510.86722]\n",
            "action: [[0. 0.]] / reward: [-1362.2084]\n",
            "action: [[0. 0.]] / reward: [340.5573]\n",
            "action: [[0. 0.]] / reward: [-681.125]\n",
            "action: [[0. 0.]] / reward: [85.15495]\n",
            "action: [[0. 0.]] / reward: [766.2279]\n",
            "action: [[0. 0.]] / reward: [-4256.9766]\n",
            "action: [[0. 1.]] / reward: [1787.931]\n",
            "action: [[0. 0.]] / reward: [-340.56772]\n",
            "action: [[0. 0.]] / reward: [1617.6628]\n",
            "action: [[1.557357 0.      ]] / reward: [-851.3828]\n",
            "action: [[1.3343979 0.       ]] / reward: [85.15495]\n",
            "action: [[0. 0.]] / reward: [2128.4883]\n",
            "action: [[0.        0.3824167]] / reward: [681.0834]\n",
            "action: [[0.         0.08787052]] / reward: [-2043.3439]\n",
            "action: [[0.0911485 0.       ]] / reward: [681.13544]\n",
            "action: [[0.2912888 0.8410328]] / reward: [0.]\n",
            "action: [[1.4495904 0.       ]] / reward: [-1106.806]\n",
            "action: [[0.18812774 0.8911941 ]] / reward: [510.82553]\n",
            "action: [[0.33647257 0.        ]] / reward: [-2128.4883]\n",
            "action: [[0. 1.]] / reward: [936.5378]\n",
            "action: [[0. 0.]] / reward: [170.25781]\n",
            "action: [[0.6882993 0.       ]] / reward: [-1277.0951]\n",
            "action: [[0.1329704  0.72553146]] / reward: [2298.7878]\n",
            "action: [[0.22890365 0.        ]] / reward: [2213.6016]\n",
            "action: [[0.07128966 0.        ]] / reward: [681.125]\n",
            "action: [[1.8917465 0.       ]] / reward: [936.5378]\n",
            "action: [[0.06413579 0.        ]] / reward: [936.5378]\n",
            "action: [[1.3789028  0.06148654]] / reward: [255.41277]\n",
            "action: [[0.        0.9416075]] / reward: [1532.5183]\n",
            "action: [[0.61905694 0.        ]] / reward: [-510.82553]\n",
            "action: [[0. 0.]] / reward: [1106.7957]\n",
            "action: [[0.23047116 0.        ]] / reward: [-1787.9207]\n",
            "action: [[0. 0.]] / reward: [851.3828]\n",
            "action: [[0. 0.]] / reward: [-681.125]\n",
            "action: [[1.2220995 0.       ]] / reward: [340.5573]\n",
            "action: [[0. 0.]] / reward: [766.27997]\n",
            "action: [[0. 0.]] / reward: [766.2383]\n",
            "action: [[0. 1.]] / reward: [1191.9506]\n",
            "action: [[0.3992242  0.08437467]] / reward: [-2809.5718]\n",
            "action: [[1.0014784 0.       ]] / reward: [170.25781]\n",
            "action: [[0. 0.]] / reward: [-1787.9207]\n",
            "action: [[0.04252136 0.        ]] / reward: [425.71225]\n",
            "action: [[0.        0.4069095]] / reward: [255.41277]\n",
            "action: [[0.        0.3350721]] / reward: [-255.41277]\n",
            "action: [[0.        0.5517586]] / reward: [-2979.9233]\n",
            "action: [[1.1877145  0.41609523]] / reward: [766.27997]\n",
            "action: [[0.8285632 0.       ]] / reward: [1787.931]\n",
            "action: [[0. 0.]] / reward: [681.125]\n",
            "action: [[0. 1.]] / reward: [-2128.4883]\n",
            "action: [[0. 1.]] / reward: [595.9701]\n",
            "action: [[0. 0.]] / reward: [1617.6211]\n",
            "action: [[0.23179354 0.        ]] / reward: [85.15495]\n",
            "action: [[1.8578739 0.3870451]] / reward: [681.125]\n",
            "action: [[0. 0.]] / reward: [-1106.7957]\n",
            "action: [[0.         0.08271885]] / reward: [-595.98047]\n",
            "action: [[0.         0.06210938]] / reward: [1106.806]\n",
            "action: [[0.14061911 1.        ]] / reward: [1532.5078]\n",
            "action: [[0.15219973 0.        ]] / reward: [1021.65106]\n",
            "action: [[0.3685893  0.00587749]] / reward: [-510.82553]\n",
            "action: [[0.         0.09406951]] / reward: [-1277.1055]\n",
            "action: [[0.         0.28420022]] / reward: [-1106.7957]\n",
            "action: [[0.00516793 0.31813648]] / reward: [1021.69275]\n",
            "action: [[0.26035684 0.62110496]] / reward: [-1021.69275]\n",
            "action: [[1.8662574 0.       ]] / reward: [-1191.9506]\n",
            "action: [[0.17944336 0.        ]] / reward: [-2469.0562]\n",
            "action: [[0.00978595 0.        ]] / reward: [-595.9701]\n",
            "action: [[0. 0.]] / reward: [-681.125]\n",
            "action: [[0. 0.]] / reward: [-3064.9844]\n",
            "action: [[0.47551695 0.05389106]] / reward: [2128.4468]\n",
            "action: [[0. 0.]] / reward: [-510.82553]\n",
            "action: [[0. 0.]] / reward: [-3150.1394]\n",
            "action: [[0.5656423  0.21363813]] / reward: [595.9753]\n",
            "action: [[2.2232902 0.       ]] / reward: [-2043.3802]\n",
            "action: [[0. 0.]] / reward: [-2937.278]\n",
            "action: [[0.31386954 0.        ]] / reward: [-1447.405]\n",
            "action: [[0. 0.]] / reward: [2341.3445]\n",
            "action: [[0. 0.]] / reward: [2383.9011]\n",
            "action: [[0.         0.65243536]] / reward: [255.41277]\n",
            "action: [[0.6456742 0.       ]] / reward: [425.71747]\n",
            "action: [[0. 1.]] / reward: [425.71225]\n",
            "action: [[0.8233319 0.       ]] / reward: [510.82553]\n",
            "action: [[0.03077017 0.        ]] / reward: [936.5378]\n",
            "action: [[0. 1.]] / reward: [1277.1055]\n",
            "action: [[0.         0.19839567]] / reward: [-1191.9506]\n",
            "action: [[0. 1.]] / reward: [425.6706]\n",
            "action: [[1.006408 0.      ]] / reward: [2043.3334]\n",
            "action: [[0. 0.]] / reward: [-1191.9506]\n",
            "action: [[0. 0.]] / reward: [-85.10287]\n",
            "action: [[0. 1.]] / reward: [1447.3633]\n",
            "action: [[0.         0.59094673]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [4001.564]\n",
            "action: [[0. 0.]] / reward: [1191.9506]\n",
            "action: [[0. 0.]] / reward: [-2043.3855]\n",
            "action: [[0. 0.]] / reward: [1191.9506]\n",
            "action: [[0.35250556 0.        ]] / reward: [-2979.871]\n",
            "action: [[0. 0.]] / reward: [-766.2383]\n",
            "action: [[0.         0.28047308]] / reward: [-936.5378]\n",
            "action: [[0.7511749 0.       ]] / reward: [2724.4688]\n",
            "action: [[0. 0.]] / reward: [7407.116]\n",
            "action: [[0. 0.]] / reward: [1617.6628]\n",
            "action: [[0. 1.]] / reward: [1532.5078]\n",
            "action: [[0.5413713 0.       ]] / reward: [2043.3439]\n",
            "action: [[0. 0.]] / reward: [4512.3896]\n",
            "action: [[0.90415335 0.        ]] / reward: [-2554.159]\n",
            "action: [[0.8413311 0.       ]] / reward: [255.41277]\n",
            "action: [[0.71308553 0.        ]] / reward: [1191.9506]\n",
            "action: [[0. 0.]] / reward: [-1277.1055]\n",
            "action: [[0. 0.]] / reward: [-1106.7957]\n",
            "action: [[0. 1.]] / reward: [681.125]\n",
            "action: [[0.         0.12917964]] / reward: [1702.7761]\n",
            "action: [[0. 1.]] / reward: [1702.7656]\n",
            "action: [[1.4224434 0.       ]] / reward: [-340.5573]\n",
            "action: [[0. 1.]] / reward: [-936.5378]\n",
            "action: [[0.        0.5635265]] / reward: [595.9701]\n",
            "action: [[0. 0.]] / reward: [2469.0562]\n",
            "action: [[0.        0.4145688]] / reward: [-4256.9766]\n",
            "action: [[0.         0.33133426]] / reward: [-255.41277]\n",
            "action: [[0. 0.]] / reward: [-5193.5146]\n",
            "action: [[0.08149996 0.5269372 ]] / reward: [-595.98047]\n",
            "action: [[1.0245659 0.       ]] / reward: [1702.8177]\n",
            "action: [[0.61288786 0.        ]] / reward: [-1787.9207]\n",
            "action: [[0.10294802 1.        ]] / reward: [2809.5718]\n",
            "action: [[0.03422931 0.        ]] / reward: [2724.4585]\n",
            "action: [[0.3982272 0.5981008]] / reward: [1532.5183]\n",
            "action: [[0.4312283  0.46578485]] / reward: [1787.9207]\n",
            "action: [[2.258859   0.67484844]] / reward: [-1162.7042]\n",
            "action: [[1.0451169 0.       ]] / reward: [332.20798]\n",
            "action: [[0.4523142 0.4799079]] / reward: [1024.282]\n",
            "action: [[0.53716874 0.        ]] / reward: [332.20798]\n",
            "action: [[0.0854681 1.       ]] / reward: [719.7727]\n",
            "action: [[0. 0.]] / reward: [-332.2046]\n",
            "action: [[0. 0.]] / reward: [387.56808]\n",
            "action: [[0.        0.7577007]] / reward: [-664.4024]\n",
            "action: [[0. 0.]] / reward: [27.688515]\n",
            "action: [[0. 0.]] / reward: [332.19446]\n",
            "action: [[0. 0.]] / reward: [-249.14583]\n",
            "action: [[0.56659853 1.        ]] / reward: [-802.8247]\n",
            "action: [[0.06280507 0.8209498 ]] / reward: [941.2334]\n",
            "action: [[0.96815854 0.        ]] / reward: [-193.78574]\n",
            "action: [[0. 0.]] / reward: [-304.51947]\n",
            "action: [[0.45432702 0.        ]] / reward: [-387.56808]\n",
            "action: [[0. 0.]] / reward: [-609.0254]\n",
            "action: [[0.29304928 0.        ]] / reward: [-1356.5001]\n",
            "action: [[0. 1.]] / reward: [-276.83435]\n",
            "action: [[0.       0.990835]] / reward: [138.42564]\n",
            "action: [[0. 0.]] / reward: [-1079.659]\n",
            "action: [[0.56538284 0.        ]] / reward: [193.78574]\n",
            "action: [[0. 0.]] / reward: [498.3052]\n",
            "action: [[1.1260636 0.       ]] / reward: [83.04523]\n",
            "action: [[1.4796951  0.28209147]] / reward: [-1396.6742]\n",
            "action: [[0.23236263 0.        ]] / reward: [135.15456]\n",
            "action: [[0.08962214 0.        ]] / reward: [630.7598]\n",
            "action: [[0.6751975 0.       ]] / reward: [765.9199]\n",
            "action: [[0.7986123 1.       ]] / reward: [1171.4221]\n",
            "action: [[3. 0.]] / reward: [-1621.9594]\n",
            "action: [[0.38823688 0.        ]] / reward: [-2568.1018]\n",
            "action: [[0.         0.03057507]] / reward: [901.07996]\n",
            "action: [[0. 0.]] / reward: [135.16006]\n",
            "action: [[0.01408567 1.        ]] / reward: [-2838.4219]\n",
            "action: [[2.192703 0.      ]] / reward: [405.50226]\n",
            "action: [[0.4987523 0.3415571]] / reward: [1486.7772]\n",
            "action: [[0.         0.22109655]] / reward: [585.72485]\n",
            "action: [[0.        0.6021157]] / reward: [-1621.9594]\n",
            "action: [[0.25958914 1.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [-675.8224]\n",
            "action: [[0. 0.]] / reward: [-1171.4221]\n",
            "action: [[0. 0.]] / reward: [1576.9244]\n",
            "action: [[0.35480142 1.        ]] / reward: [450.53723]\n",
            "action: [[0.22812624 1.        ]] / reward: [360.44522]\n",
            "action: [[0.8160745 1.       ]] / reward: [-315.40472]\n",
            "action: [[0. 0.]] / reward: [180.2171]\n",
            "action: [[0.14285673 0.9499994 ]] / reward: [315.38266]\n",
            "action: [[0.36830014 0.        ]] / reward: [270.34216]\n",
            "action: [[0.         0.61322486]] / reward: [-90.11957]\n",
            "action: [[1.1028014 0.3018377]] / reward: [946.4972]\n",
            "action: [[0.03779243 0.18059762]] / reward: [59.129837]\n",
            "action: [[0.        0.4645605]] / reward: [-2839.4336]\n",
            "action: [[0.        0.8867514]] / reward: [-1656.3447]\n",
            "action: [[0. 0.]] / reward: [1123.9591]\n",
            "action: [[0.8174623 0.       ]] / reward: [473.21964]\n",
            "action: [[1.021102 0.      ]] / reward: [-473.21964]\n",
            "action: [[1.4769847 0.       ]] / reward: [650.6815]\n",
            "action: [[0. 0.]] / reward: [769.0353]\n",
            "action: [[0.5440403 1.       ]] / reward: [1656.3447]\n",
            "action: [[0.         0.09621248]] / reward: [709.84753]\n",
            "action: [[0.32991263 0.        ]] / reward: [354.95273]\n",
            "action: [[0.8453901 0.       ]] / reward: [473.2486]\n",
            "action: [[0.13669617 1.        ]] / reward: [-1360.587]\n",
            "action: [[0. 0.]] / reward: [1242.2622]\n",
            "action: [[1.0983486 1.       ]] / reward: [-453.8765]\n",
            "action: [[0. 0.]] / reward: [-272.38144]\n",
            "action: [[0.        0.5049502]] / reward: [-1361.685]\n",
            "action: [[0. 0.]] / reward: [-1634.0665]\n",
            "action: [[0.        0.4308382]] / reward: [363.13452]\n",
            "action: [[0.08395442 0.        ]] / reward: [0.]\n",
            "action: [[0.         0.59752125]] / reward: [-907.85297]\n",
            "action: [[0.9817433 0.8136926]] / reward: [-2087.932]\n",
            "action: [[0. 0.]] / reward: [90.78641]\n",
            "action: [[0.         0.32371414]] / reward: [90.75309]\n",
            "action: [[0.        0.6026312]] / reward: [-272.337]\n",
            "action: [[0.34954923 0.53293717]] / reward: [-998.595]\n",
            "action: [[0.       0.397802]] / reward: [1906.3923]\n",
            "action: [[0. 0.]] / reward: [-1361.674]\n",
            "action: [[0. 0.]] / reward: [272.337]\n",
            "action: [[0. 0.]] / reward: [-272.337]\n",
            "action: [[3. 0.]] / reward: [907.7974]\n",
            "action: [[0. 0.]] / reward: [2723.4146]\n",
            "action: [[0. 0.]] / reward: [3086.5823]\n",
            "action: [[0.        0.7288315]] / reward: [-2451.1218]\n",
            "action: [[0. 1.]] / reward: [907.7974]\n",
            "action: [[1.0292426 0.       ]] / reward: [726.26904]\n",
            "action: [[1.6685727 0.       ]] / reward: [-272.337]\n",
            "action: [[0. 0.]] / reward: [363.1234]\n",
            "action: [[0. 0.]] / reward: [-7807.176]\n",
            "action: [[0.         0.30498606]] / reward: [1361.7295]\n",
            "action: [[1.016668   0.80418265]] / reward: [-2360.3245]\n",
            "action: [[0.7557622 0.       ]] / reward: [-3358.875]\n",
            "action: [[0. 0.]] / reward: [2087.9429]\n",
            "action: [[0. 0.]] / reward: [1634.0554]\n",
            "action: [[0.         0.12922248]] / reward: [181.59503]\n",
            "action: [[1.1400898 0.       ]] / reward: [1361.674]\n",
            "action: [[0.        0.6336658]] / reward: [2087.9873]\n",
            "action: [[0.58440465 0.48535594]] / reward: [-1180.1344]\n",
            "action: [[0. 1.]] / reward: [4357.4697]\n",
            "action: [[0.09551513 0.        ]] / reward: [-2087.9873]\n",
            "action: [[0.70626414 0.45262071]] / reward: [272.38144]\n",
            "action: [[0. 0.]] / reward: [-4629.851]\n",
            "action: [[0.         0.29777595]] / reward: [453.92093]\n",
            "action: [[0.25817952 0.31251308]] / reward: [-635.46045]\n",
            "action: [[0.12189323 0.        ]] / reward: [-998.595]\n",
            "action: [[0. 0.]] / reward: [1815.606]\n",
            "action: [[0.        0.7788695]] / reward: [1361.7184]\n",
            "action: [[0.         0.39162463]] / reward: [2814.201]\n",
            "action: [[0. 0.]] / reward: [-726.25793]\n",
            "action: [[0.        0.5339402]] / reward: [1361.7295]\n",
            "action: [[1.7845161 1.       ]] / reward: [998.595]\n",
            "action: [[0.00808866 0.        ]] / reward: [-726.25793]\n",
            "action: [[0.         0.04111279]] / reward: [2269.5269]\n",
            "action: [[0. 0.]] / reward: [907.7974]\n",
            "action: [[0. 1.]] / reward: [2632.6614]\n",
            "action: [[0. 0.]] / reward: [-544.674]\n",
            "action: [[0.         0.27138633]] / reward: [1815.606]\n",
            "action: [[0.81891197 0.        ]] / reward: [1543.2689]\n",
            "action: [[0. 0.]] / reward: [363.1234]\n",
            "action: [[0.59003973 0.7565677 ]] / reward: [-1452.4714]\n",
            "action: [[1.2424943  0.02824572]] / reward: [-4539.0537]\n",
            "action: [[0.        0.6749482]] / reward: [4175.9194]\n",
            "action: [[0.35765624 1.        ]] / reward: [5537.6597]\n",
            "action: [[0. 0.]] / reward: [-544.71844]\n",
            "action: [[1.6979349 0.       ]] / reward: [1180.1788]\n",
            "action: [[0.81157446 0.        ]] / reward: [363.13452]\n",
            "action: [[0. 0.]] / reward: [-4448.312]\n",
            "action: [[0.         0.18543136]] / reward: [1906.4479]\n",
            "action: [[0.03971989 0.18899965]] / reward: [998.55054]\n",
            "action: [[1.4836229 0.       ]] / reward: [-1724.8085]\n",
            "action: [[0.85227114 0.        ]] / reward: [-998.595]\n",
            "action: [[0.         0.37983352]] / reward: [816.99994]\n",
            "action: [[0.09672469 1.        ]] / reward: [1997.19]\n",
            "action: [[0.         0.03540212]] / reward: [544.674]\n",
            "action: [[0.        0.6627841]] / reward: [-635.46045]\n",
            "action: [[0. 1.]] / reward: [181.58392]\n",
            "action: [[0.         0.25869834]] / reward: [907.80853]\n",
            "action: [[0. 0.]] / reward: [544.6629]\n",
            "action: [[0. 1.]] / reward: [3086.5823]\n",
            "action: [[0. 0.]] / reward: [-181.58392]\n",
            "action: [[0. 0.]] / reward: [-544.674]\n",
            "action: [[0. 1.]] / reward: [1906.4034]\n",
            "action: [[0. 1.]] / reward: [-907.80853]\n",
            "action: [[0. 0.]] / reward: [-1089.3925]\n",
            "action: [[0.05120301 1.        ]] / reward: [-1452.4714]\n",
            "action: [[0. 1.]] / reward: [635.47156]\n",
            "action: [[0.7899146  0.11353026]] / reward: [1543.2689]\n",
            "action: [[0.96012366 0.        ]] / reward: [998.595]\n",
            "action: [[1.299016 0.      ]] / reward: [90.78641]\n",
            "action: [[1.7215198 1.       ]] / reward: [-181.58392]\n",
            "action: [[0. 1.]] / reward: [-544.674]\n",
            "action: [[0.         0.38915426]] / reward: [-4357.514]\n",
            "action: [[0.         0.85545194]] / reward: [1089.3925]\n",
            "action: [[0. 0.]] / reward: [-181.53949]\n",
            "action: [[0.         0.19631277]] / reward: [1815.606]\n",
            "action: [[1.4526782 0.       ]] / reward: [-998.595]\n",
            "action: [[0.         0.79357135]] / reward: [907.7974]\n",
            "action: [[0. 0.]] / reward: [453.92093]\n",
            "action: [[0. 0.]] / reward: [-907.7974]\n",
            "action: [[2.0173774  0.33794546]] / reward: [420.71204]\n",
            "action: [[1.0673869 1.       ]] / reward: [-1631.144]\n",
            "action: [[0. 0.]] / reward: [1902.9957]\n",
            "action: [[0.16828695 0.        ]] / reward: [996.81573]\n",
            "action: [[0.         0.13637805]] / reward: [1631.155]\n",
            "action: [[0.         0.46514583]] / reward: [-2265.4834]\n",
            "action: [[0.9121587 0.       ]] / reward: [2174.8477]\n",
            "action: [[2.356807 0.      ]] / reward: [1268.6676]\n",
            "action: [[1.2081542 0.       ]] / reward: [0.]\n",
            "action: [[0.02503163 0.        ]] / reward: [-2537.3352]\n",
            "action: [[0. 1.]] / reward: [1540.5193]\n",
            "action: [[1.0978124 1.       ]] / reward: [-815.55536]\n",
            "action: [[0.23049589 1.        ]] / reward: [-2356.108]\n",
            "action: [[1.6568698 0.       ]] / reward: [1721.7798]\n",
            "action: [[0.         0.00898185]] / reward: [634.32825]\n",
            "action: [[0.31409776 0.07936814]] / reward: [-1721.7798]\n",
            "action: [[0.         0.32796532]] / reward: [0.]\n",
            "action: [[0.        0.6361314]] / reward: [1812.3711]\n",
            "action: [[0.         0.82236844]] / reward: [1993.6315]\n",
            "action: [[0. 0.]] / reward: [2174.8586]\n",
            "action: [[0.2559244 0.3110897]] / reward: [1268.6676]\n",
            "action: [[0.8330397 1.       ]] / reward: [634.37256]\n",
            "action: [[1.1042681  0.09950605]] / reward: [543.70355]\n",
            "action: [[2.0054345 0.       ]] / reward: [-634.32825]\n",
            "action: [[0. 0.]] / reward: [1268.6676]\n",
            "action: [[0. 1.]] / reward: [724.964]\n",
            "action: [[0. 0.]] / reward: [-1993.6315]\n",
            "action: [[0. 0.]] / reward: [271.8407]\n",
            "action: [[1.0093044  0.92739016]] / reward: [634.3393]\n",
            "action: [[0.01333212 0.        ]] / reward: [1178.0319]\n",
            "action: [[0. 1.]] / reward: [1268.6676]\n",
            "action: [[0. 0.]] / reward: [2809.2312]\n",
            "action: [[0. 0.]] / reward: [724.9196]\n",
            "action: [[0.5049294 0.       ]] / reward: [-1540.5193]\n",
            "action: [[1.253171 0.      ]] / reward: [1178.0428]\n",
            "action: [[0. 0.]] / reward: [-362.44318]\n",
            "action: [[0. 0.]] / reward: [906.1911]\n",
            "action: [[0.9376806 0.       ]] / reward: [-543.7479]\n",
            "action: [[0. 0.]] / reward: [-181.21605]\n",
            "action: [[0. 1.]] / reward: [-362.48752]\n",
            "action: [[0. 0.]] / reward: [543.70355]\n",
            "action: [[0.39365044 0.        ]] / reward: [6343.382]\n",
            "action: [[0. 0.]] / reward: [1087.4071]\n",
            "action: [[1.150202 0.      ]] / reward: [-1993.5872]\n",
            "action: [[0. 0.]] / reward: [-1812.4155]\n",
            "action: [[1.5310452 0.       ]] / reward: [-1449.8947]\n",
            "action: [[0. 1.]] / reward: [1540.5193]\n",
            "action: [[0.59534967 0.        ]] / reward: [-1449.928]\n",
            "action: [[0. 0.]] / reward: [-1359.2589]\n",
            "action: [[0.         0.60174996]] / reward: [1178.0428]\n",
            "action: [[0.         0.95583785]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [-2265.4834]\n",
            "action: [[0.01485199 0.02751039]] / reward: [-4440.342]\n",
            "action: [[0. 0.]] / reward: [2990.4473]\n",
            "action: [[0. 0.]] / reward: [-4530.967]\n",
            "action: [[0.3365074  0.39091673]] / reward: [1087.4071]\n",
            "action: [[0. 0.]] / reward: [-2718.551]\n",
            "action: [[0.         0.76450384]] / reward: [1449.8835]\n",
            "action: [[0.7686813 0.       ]] / reward: [3443.5596]\n",
            "action: [[0.5692045 0.       ]] / reward: [-1178.0762]\n",
            "action: [[1.6152182 0.       ]] / reward: [-724.964]\n",
            "action: [[0.5707735  0.20776658]] / reward: [-3443.5261]\n",
            "action: [[0. 0.]] / reward: [1903.0068]\n",
            "action: [[0. 0.]] / reward: [-90.59139]\n",
            "action: [[0.25877324 0.31626573]] / reward: [3171.6743]\n",
            "action: [[2.2655485 0.       ]] / reward: [1449.8835]\n",
            "action: [[0.9875216 0.       ]] / reward: [1631.155]\n",
            "action: [[0.94352573 0.        ]] / reward: [-1087.4515]\n",
            "action: [[0.        0.3947189]] / reward: [-453.06784]\n",
            "action: [[1.9046934 0.       ]] / reward: [2084.212]\n",
            "action: [[0. 0.]] / reward: [543.7479]\n",
            "action: [[0.10689074 1.        ]] / reward: [-1631.144]\n",
            "action: [[0.        0.3405404]] / reward: [634.32825]\n",
            "action: [[0.09704709 0.        ]] / reward: [815.55536]\n",
            "action: [[0.       0.890663]] / reward: [724.964]\n",
            "action: [[0.16302368 0.        ]] / reward: [1178.0319]\n",
            "action: [[0. 1.]] / reward: [-543.6925]\n",
            "action: [[0. 0.]] / reward: [1540.5193]\n",
            "action: [[0. 0.]] / reward: [-90.63574]\n",
            "action: [[0.7214308 0.       ]] / reward: [-2809.1868]\n",
            "action: [[0. 0.]] / reward: [2174.8477]\n",
            "action: [[0.16415432 0.984217  ]] / reward: [-1087.3961]\n",
            "action: [[0. 0.]] / reward: [815.54425]\n",
            "action: [[0. 0.]] / reward: [-1087.3961]\n",
            "action: [[0. 1.]] / reward: [181.21605]\n",
            "action: [[0. 1.]] / reward: [-1812.3711]\n",
            "action: [[0. 0.]] / reward: [1268.6676]\n",
            "action: [[0.0428039 0.       ]] / reward: [-2990.4473]\n",
            "action: [[0.         0.10405548]] / reward: [3624.7866]\n",
            "action: [[0.        0.7444222]] / reward: [90.62466]\n",
            "action: [[0.28598902 0.9636745 ]] / reward: [-1449.928]\n",
            "action: [[0. 1.]] / reward: [-2718.551]\n",
            "action: [[0. 0.]] / reward: [-543.7479]\n",
            "action: [[0.9639729 0.       ]] / reward: [362.47644]\n",
            "action: [[0.66224784 0.        ]] / reward: [-1087.4404]\n",
            "action: [[0. 0.]] / reward: [-724.9196]\n",
            "action: [[0.8313825  0.03219349]] / reward: [2809.1868]\n",
            "action: [[0.        0.9458529]] / reward: [996.81573]\n",
            "action: [[0. 0.]] / reward: [1993.6315]\n",
            "action: [[1.1272597  0.39084005]] / reward: [-90.63574]\n",
            "action: [[1.0268316 0.       ]] / reward: [181.21605]\n",
            "action: [[0.99415207 1.        ]] / reward: [-1268.6676]\n",
            "action: [[0. 0.]] / reward: [-1902.9957]\n",
            "action: [[0.       0.551457]] / reward: [-1178.0319]\n",
            "action: [[1.3058463 0.9084935]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [-1268.6676]\n",
            "action: [[0.07464549 0.        ]] / reward: [-3443.5261]\n",
            "action: [[0. 0.]] / reward: [1631.155]\n",
            "action: [[0. 1.]] / reward: [5437.1465]\n",
            "action: [[0.         0.28315982]] / reward: [-1540.5637]\n",
            "action: [[0.21045282 0.        ]] / reward: [-906.18]\n",
            "action: [[0.         0.63205665]] / reward: [3171.6633]\n",
            "action: [[0. 0.]] / reward: [543.7479]\n",
            "action: [[0. 0.]] / reward: [815.55536]\n",
            "action: [[0.         0.25621784]] / reward: [3534.151]\n",
            "action: [[0. 1.]] / reward: [271.85178]\n",
            "action: [[0. 0.]] / reward: [724.964]\n",
            "action: [[0. 0.]] / reward: [-362.47644]\n",
            "action: [[0. 0.]] / reward: [906.18]\n",
            "action: [[0. 0.]] / reward: [-1902.9957]\n",
            "action: [[0. 1.]] / reward: [-429.21982]\n",
            "action: [[0.59853005 0.41292405]] / reward: [1209.0531]\n",
            "action: [[0.71300626 0.        ]] / reward: [1860.0782]\n",
            "action: [[1.2384434 0.       ]] / reward: [-1023.0364]\n",
            "action: [[0. 0.]] / reward: [558.01685]\n",
            "action: [[0. 0.]] / reward: [1581.0643]\n",
            "action: [[0.         0.23792815]] / reward: [93.00835]\n",
            "action: [[0. 0.]] / reward: [930.0391]\n",
            "action: [[0. 0.]] / reward: [1488.067]\n",
            "action: [[0.         0.40614015]] / reward: [1023.0475]\n",
            "action: [[0. 0.]] / reward: [930.0391]\n",
            "action: [[0.83654904 0.03491718]] / reward: [-2232.1006]\n",
            "action: [[1.657249 0.      ]] / reward: [-4650.196]\n",
            "action: [[0.42602357 0.        ]] / reward: [1395.0587]\n",
            "action: [[0.4326092  0.21006002]] / reward: [-1023.0475]\n",
            "action: [[0. 1.]] / reward: [1395.0587]\n",
            "action: [[0.90522414 0.        ]] / reward: [837.0419]\n",
            "action: [[0. 0.]] / reward: [-372.0223]\n",
            "action: [[0.3546    0.8044347]] / reward: [-1302.0503]\n",
            "action: [[0.14965585 0.        ]] / reward: [-744.0335]\n",
            "action: [[0.36200312 1.        ]] / reward: [-186.0056]\n",
            "action: [[0.         0.25305817]] / reward: [837.03076]\n",
            "action: [[0. 0.]] / reward: [-279.01395]\n",
            "action: [[2.6136835 1.       ]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0.8750881 0.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.         0.24758282]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0.         0.35146624]] / reward: [0.]\n",
            "action: [[0.09197724 0.50956047]] / reward: [0.]\n",
            "action: [[1.847598 0.      ]] / reward: [0.]\n",
            "action: [[0.29786664 0.        ]] / reward: [0.]\n",
            "action: [[0.         0.87507236]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 1.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.        0.0799423]] / reward: [0.]\n",
            "action: [[0.7797885 1.       ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.71640503 1.        ]] / reward: [0.]\n",
            "action: [[0.         0.56317794]] / reward: [0.]\n",
            "action: [[0.21707547 0.        ]] / reward: [0.]\n",
            "action: [[0.28458384 0.        ]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.8362141 0.       ]] / reward: [0.]\n",
            "action: [[0.4150496 0.       ]] / reward: [0.]\n",
            "action: [[0.         0.35966092]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.6580306  0.36618224]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[1.2109184  0.42567468]] / reward: [-245.28885]\n",
            "action: [[1.5685625 0.       ]] / reward: [-531.4665]\n",
            "action: [[0. 0.]] / reward: [-735.8763]\n",
            "action: [[0. 0.]] / reward: [-81.76782]\n",
            "action: [[0. 1.]] / reward: [-408.8196]\n",
            "action: [[0.76193595 0.88264537]] / reward: [81.76782]\n",
            "action: [[0.9635229 0.       ]] / reward: [327.0518]\n",
            "action: [[0. 0.]] / reward: [122.64686]\n",
            "action: [[1.1695272 1.       ]] / reward: [292.28604]\n",
            "action: [[0. 1.]] / reward: [3409.9768]\n",
            "action: [[0. 1.]] / reward: [-779.41394]\n",
            "action: [[0.40565008 1.        ]] / reward: [-487.15115]\n",
            "action: [[0. 0.]] / reward: [-97.42094]\n",
            "action: [[0.40079606 0.        ]] / reward: [974.27905]\n",
            "action: [[1.22065   0.8722806]] / reward: [-2045.9907]\n",
            "action: [[0. 0.]] / reward: [-974.27905]\n",
            "action: [[0.11983109 0.        ]] / reward: [-3312.556]\n",
            "action: [[0.6254018  0.85999453]] / reward: [-1558.8396]\n",
            "action: [[0. 0.]] / reward: [-1266.5651]\n",
            "action: [[0.4764076 0.       ]] / reward: [2630.5513]\n",
            "action: [[0.         0.54838467]] / reward: [-876.8465]\n",
            "action: [[0.32756066 0.        ]] / reward: [-682.00464]\n",
            "action: [[0. 0.]] / reward: [-4579.1094]\n",
            "action: [[0.5512303 0.       ]] / reward: [-584.5721]\n",
            "action: [[1.0802381  0.81242615]] / reward: [2630.5627]\n",
            "action: [[1.043513 0.      ]] / reward: [974.27905]\n",
            "action: [[1.7451792 0.       ]] / reward: [-2240.8442]\n",
            "action: [[0.5566248 0.374755 ]] / reward: [2825.4045]\n",
            "action: [[1.4337156 0.945856 ]] / reward: [194.86511]\n",
            "action: [[0.21489234 1.        ]] / reward: [-1558.8512]\n",
            "action: [[0.04930314 0.        ]] / reward: [-1753.7046]\n",
            "action: [[0. 0.]] / reward: [974.27905]\n",
            "action: [[0.        0.0694244]] / reward: [1948.5581]\n",
            "action: [[0.        0.7255579]] / reward: [-681.99304]\n",
            "action: [[0.         0.02243406]] / reward: [-1363.9977]\n",
            "action: [[0. 0.]] / reward: [-2045.9791]\n",
            "action: [[0.9738224 0.       ]] / reward: [-389.7186]\n",
            "action: [[0.846748 0.      ]] / reward: [1558.8512]\n",
            "action: [[0. 1.]] / reward: [-1656.2721]\n",
            "action: [[0.34200004 0.        ]] / reward: [389.70697]\n",
            "action: [[0.59015274 1.        ]] / reward: [-1851.1372]\n",
            "action: [[1.0019777 0.       ]] / reward: [1558.8512]\n",
            "action: [[1.6339898 0.       ]] / reward: [3604.8418]\n",
            "action: [[0.06609783 0.92370343]] / reward: [-682.00464]\n",
            "action: [[0.03344324 0.        ]] / reward: [2922.8489]\n",
            "action: [[0. 0.]] / reward: [2630.5513]\n",
            "action: [[0. 0.]] / reward: [-584.5721]\n",
            "action: [[0.         0.35908118]] / reward: [1461.4302]\n",
            "action: [[0. 0.]] / reward: [-974.2907]\n",
            "action: [[0.0770095 0.       ]] / reward: [779.4256]\n",
            "action: [[0.6749182  0.07996666]] / reward: [-97.42094]\n",
            "action: [[0. 0.]] / reward: [584.5605]\n",
            "action: [[0. 1.]] / reward: [6430.2583]\n",
            "action: [[0. 0.]] / reward: [876.8465]\n",
            "action: [[0.09685737 0.05323918]] / reward: [-2143.4116]\n",
            "action: [[0.4471194 0.9052574]] / reward: [2045.9791]\n",
            "action: [[0.         0.36984983]] / reward: [-584.5605]\n",
            "action: [[0.         0.18027198]] / reward: [-487.13953]\n",
            "action: [[0.12127617 0.        ]] / reward: [1461.4186]\n",
            "action: [[0. 0.]] / reward: [876.8465]\n",
            "action: [[1.2564816 0.       ]] / reward: [389.7186]\n",
            "action: [[0.        0.3253799]] / reward: [292.28604]\n",
            "action: [[0.7966731 1.       ]] / reward: [487.13953]\n",
            "action: [[0.8119061  0.27174044]] / reward: [-389.7186]\n",
            "action: [[1.5410224 0.       ]] / reward: [1851.1372]\n",
            "action: [[0.         0.87117475]] / reward: [2143.4116]\n",
            "action: [[0.54390883 0.        ]] / reward: [-1461.4186]\n",
            "action: [[0.        0.3684722]] / reward: [1461.4186]\n",
            "action: [[0.7059936 0.       ]] / reward: [2240.8442]\n",
            "action: [[1.5420928 0.       ]] / reward: [-1266.5651]\n",
            "action: [[0.28451723 0.        ]] / reward: [1169.1326]\n",
            "action: [[0.48052034 0.        ]] / reward: [-2630.5513]\n",
            "action: [[0. 0.]] / reward: [97.432556]\n",
            "action: [[0.        0.7244379]] / reward: [-779.4256]\n",
            "action: [[0. 0.]] / reward: [2435.6978]\n",
            "action: [[0.88034403 0.        ]] / reward: [-292.28604]\n",
            "action: [[0.9829397  0.21616855]] / reward: [-292.28604]\n",
            "action: [[0. 0.]] / reward: [1169.1442]\n",
            "action: [[0.8143185 0.       ]] / reward: [-97.432556]\n",
            "action: [[0. 0.]] / reward: [-194.85349]\n",
            "action: [[1.1696355 0.       ]] / reward: [-1558.8512]\n",
            "action: [[0. 0.]] / reward: [0.]\n",
            "action: [[0.35722882 0.        ]] / reward: [-1656.2721]\n",
            "action: [[1.3281634 0.       ]] / reward: [1851.1256]\n",
            "action: [[0.         0.86004865]] / reward: [4091.9814]\n",
            "action: [[1.1102264 0.       ]] / reward: [-2045.9907]\n",
            "action: [[0.        0.4811145]] / reward: [2533.1301]\n",
            "action: [[1.5004278 0.0886579]] / reward: [0.]\n",
            "action: [[0. 0.]] / reward: [3799.6953]\n",
            "action: [[0. 1.]] / reward: [779.41394]\n",
            "action: [[0. 1.]] / reward: [-1266.5535]\n",
            "action: [[0.         0.23083521]] / reward: [-2630.5627]\n",
            "action: [[1.0280411 0.       ]] / reward: [-3897.1162]\n",
            "action: [[0. 0.]] / reward: [-292.28604]\n",
            "action: [[0.05964617 0.05393272]] / reward: [-2922.8372]\n",
            "action: [[0.         0.34118333]] / reward: [-3020.2698]\n",
            "action: [[0.         0.60512316]] / reward: [876.8465]\n",
            "action: [[0.2119528 0.       ]] / reward: [1363.9977]\n",
            "action: [[0.9021427 0.3364891]] / reward: [2435.6978]\n",
            "action: [[1.0864949  0.61767215]] / reward: [-1558.8512]\n",
            "action: [[0.41049626 0.86417675]] / reward: [1461.4186]\n",
            "action: [[0.45026156 0.        ]] / reward: [-487.13953]\n",
            "action: [[0.7216279 0.       ]] / reward: [1266.5651]\n",
            "action: [[0. 0.]] / reward: [-4871.3955]\n",
            "action: [[0.        0.2124345]] / reward: [-584.5721]\n",
            "action: [[1.0534512 0.       ]] / reward: [1558.8512]\n",
            "action: [[0.52259016 0.37482083]] / reward: [681.99304]\n",
            "action: [[0.9028626 0.6925976]] / reward: [194.85349]\n",
            "action: [[0. 0.]] / reward: [389.7186]\n",
            "action: [[0.         0.30666646]] / reward: [3117.6907]\n",
            "action: [[0.7974496 0.847138 ]] / reward: [-1363.9861]\n",
            "action: [[1.4249705 0.       ]] / reward: [-876.85815]\n",
            "action: [[1.4217415  0.85098547]] / reward: [-1363.9861]\n",
            "action: [[0.         0.08672426]] / reward: [2825.4163]\n",
            "action: [[0.         0.49181956]] / reward: [-1461.4302]\n",
            "action: [[0.2521541  0.99433756]] / reward: [-487.13953]\n",
            "action: [[0.79646397 0.18227531]] / reward: [1461.4186]\n",
            "action: [[0.63924515 0.        ]] / reward: [-1753.693]\n",
            "action: [[0. 0.]] / reward: [-682.00464]\n",
            "action: [[0.        0.5458598]] / reward: [-194.85349]\n",
            "action: [[0. 1.]] / reward: [1266.5651]\n",
            "action: [[0. 0.]] / reward: [-389.70697]\n",
            "action: [[0.        0.5492866]] / reward: [-1461.4302]\n",
            "action: [[0. 0.]] / reward: [97.432556]\n",
            "action: [[0. 0.]] / reward: [1363.9977]\n",
            "action: [[1.4595398  0.03422034]] / reward: [-2825.4163]\n",
            "action: [[0.20944211 0.        ]] / reward: [292.28604]\n",
            "action: [[0. 1.]] / reward: [1071.7]\n",
            "action: [[0. 0.]] / reward: [-3117.6907]\n",
            "action: [[0. 0.]] / reward: [-1753.7046]\n",
            "action: [[0.37856197 0.        ]] / reward: [2435.6978]\n",
            "action: [[0.18942836 0.        ]] / reward: [779.4256]\n",
            "action: [[0. 0.]] / reward: [-1753.7046]\n",
            "action: [[0.         0.22669503]] / reward: [5650.821]\n",
            "action: [[0.2319377 0.       ]] / reward: [-1461.4186]\n",
            "action: [[2.0701225 0.       ]] / reward: [3312.556]\n",
            "action: [[0. 0.]] / reward: [-974.27905]\n",
            "action: [[1.0053872 0.       ]] / reward: [-389.7186]\n",
            "action: [[1.0614841 0.       ]] / reward: [974.2907]\n",
            "action: [[0. 0.]] / reward: [1071.7]\n",
            "action: [[0.57518446 1.        ]] / reward: [779.4256]\n",
            "action: [[0.12201631 0.        ]] / reward: [2338.2769]\n",
            "action: [[0. 1.]] / reward: [1558.8396]\n",
            "action: [[0.48346427 0.        ]] / reward: [1363.9977]\n",
            "action: [[1.4656854 0.6424886]] / reward: [876.8465]\n",
            "action: [[0. 0.]] / reward: [2338.2769]\n",
            "action: [[0. 1.]] / reward: [3799.6953]\n",
            "action: [[0.678225 0.      ]] / reward: [-1363.9977]\n",
            "action: [[0.         0.05594265]] / reward: [-194.85349]\n",
            "action: [[1.020936   0.40020013]] / reward: [681.99304]\n",
            "action: [[0.3515396 1.       ]] / reward: [-2143.4116]\n",
            "action: [[0. 0.]] / reward: [1071.7117]\n",
            "action: [[0.        0.6393465]] / reward: [487.13953]\n",
            "action: [[0.7704277 0.4779461]] / reward: [-97.432556]\n",
            "action: [[0. 0.]] / reward: [-2338.2769]\n",
            "action: [[0.        0.7853031]] / reward: [779.4256]\n",
            "action: [[0. 0.]] / reward: [-974.27905]\n",
            "action: [[0.         0.17015961]] / reward: [-3020.2698]\n",
            "action: [[0. 0.]] / reward: [1656.2837]\n",
            "action: [[0.10450798 0.        ]] / reward: [1169.1326]\n",
            "action: [[0. 1.]] / reward: [-1071.7117]\n",
            "action: [[0. 0.]] / reward: [2045.9907]\n",
            "action: [[1.402686 0.      ]] / reward: [1266.5651]\n",
            "action: [[0. 0.]] / reward: [194.85349]\n",
            "action: [[0.         0.86521584]] / reward: [-3507.4092]\n",
            "action: [[0. 1.]] / reward: [584.5721]\n",
            "action: [[0.7649719 0.4102672]] / reward: [1071.7117]\n",
            "action: [[0. 1.]] / reward: [-3702.2744]\n",
            "action: [[0. 0.]] / reward: [2240.8442]\n",
            "action: [[0. 1.]] / reward: [4286.835]\n",
            "action: [[0.36604327 0.        ]] / reward: [1851.1372]\n",
            "action: [[0.9393194 0.       ]] / reward: [2435.6978]\n",
            "action: [[0. 0.]] / reward: [3604.8303]\n",
            "action: [[0. 1.]] / reward: [779.4256]\n",
            "action: [[0. 0.]] / reward: [1071.7117]\n",
            "action: [[0.935152 0.      ]] / reward: [3994.5488]\n",
            "action: [[1.6031438 0.       ]] / reward: [1363.9861]\n",
            "action: [[0. 0.]] / reward: [1753.7046]\n",
            "action: [[0.5251047 0.       ]] / reward: [-681.99304]\n",
            "action: [[0. 0.]] / reward: [-3020.2698]\n",
            "action: [[0.         0.99850625]] / reward: [-194.85349]\n",
            "action: [[1.301765   0.91058487]] / reward: [681.99304]\n",
            "action: [[0. 0.]] / reward: [682.00464]\n",
            "action: [[0.3417803  0.91584426]] / reward: [-2435.7092]\n",
            "action: [[0.7855847 1.       ]] / reward: [-11691.36]\n",
            "action: [[0. 0.]] / reward: [2143.4233]\n",
            "action: [[0.         0.17318034]] / reward: [-2240.8442]\n",
            "action: [[0.00609767 0.        ]] / reward: [-1558.8512]\n",
            "action: [[1.1171255 0.       ]] / reward: [1169.1326]\n",
            "action: [[0. 0.]] / reward: [2630.5627]\n",
            "action: [[0.        0.3256889]] / reward: [2045.9907]\n",
            "action: [[0. 1.]] / reward: [-2435.7092]\n",
            "action: [[0. 1.]] / reward: [2435.7092]\n",
            "action: [[0. 0.]] / reward: [-1266.5651]\n",
            "action: [[0.         0.33380902]] / reward: [-292.28604]\n",
            "action: [[0.        0.7182426]] / reward: [-1169.1326]\n",
            "action: [[0. 0.]] / reward: [-1071.7117]\n",
            "action: [[0.        0.4566412]] / reward: [3312.556]\n",
            "action: [[0. 0.]] / reward: [-2143.4233]\n",
            "action: [[1.0557152 1.       ]] / reward: [-2338.2651]\n",
            "action: [[0.80902123 0.        ]] / reward: [-3409.9883]\n",
            "action: [[1.3679466  0.50416565]] / reward: [2045.9907]\n",
            "action: [[0. 0.]] / reward: [-1851.1372]\n",
            "action: [[0. 0.]] / reward: [2143.4233]\n",
            "action: [[0. 0.]] / reward: [-3215.1233]\n",
            "action: [[0. 0.]] / reward: [4286.835]\n",
            "action: [[0. 0.]] / reward: [-2922.8489]\n",
            "action: [[0.7260404 1.       ]] / reward: [-779.4256]\n",
            "action: [[0.2093986 0.       ]] / reward: [-1266.5535]\n",
            "action: [[1.2426366  0.60767704]] / reward: [292.27444]\n",
            "action: [[0. 0.]] / reward: [1461.4186]\n",
            "action: [[0.11621565 0.48859894]] / reward: [682.00464]\n",
            "action: [[0.        0.6148144]] / reward: [1753.7046]\n",
            "action: [[0.         0.67647743]] / reward: [1656.2721]\n",
            "action: [[0.        0.7915355]] / reward: [-487.13953]\n",
            "action: [[0. 1.]] / reward: [-584.5721]\n",
            "action: [[0.30397552 0.31728825]] / reward: [-3117.6907]\n",
            "action: [[1.3306013  0.34835953]] / reward: [3117.6907]\n",
            "action: [[0.68898374 0.02943298]] / reward: [2143.4233]\n",
            "action: [[0.4965764 0.8541275]] / reward: [-2045.9907]\n",
            "action: [[0.8156377  0.24011698]] / reward: [-1753.7046]\n",
            "action: [[0.11515659 0.        ]] / reward: [-1071.7117]\n",
            "action: [[0.47210854 0.        ]] / reward: [-779.4256]\n",
            "action: [[0.         0.18571842]] / reward: [974.2907]\n",
            "action: [[0. 0.]] / reward: [-3507.4092]\n",
            "action: [[1.1063561 0.       ]] / reward: [2045.9791]\n",
            "action: [[1.8759177 0.       ]] / reward: [584.5721]\n",
            "action: [[0.96268415 0.        ]] / reward: [-2045.9907]\n",
            "action: [[0.         0.45648164]] / reward: [-2630.5513]\n",
            "action: [[0. 1.]] / reward: [1656.2721]\n",
            "action: [[1.355044 0.      ]] / reward: [389.7186]\n",
            "action: [[1.3182464 0.       ]] / reward: [389.70697]\n",
            "action: [[0.         0.19197726]] / reward: [-389.70697]\n",
            "action: [[0.24655321 1.        ]] / reward: [-6137.972]\n",
            "action: [[0.18969008 0.6268236 ]] / reward: [-1071.7]\n",
            "action: [[0.48014632 1.        ]] / reward: [-5845.686]\n",
            "action: [[0. 0.]] / reward: [1071.7117]\n",
            "action: [[0. 0.]] / reward: [3117.6907]\n",
            "action: [[0. 0.]] / reward: [-1363.9861]\n",
            "action: [[0.99868524 0.        ]] / reward: [584.5605]\n",
            "action: [[1.4075526 0.       ]] / reward: [1266.5651]\n",
            "action: [[0.         0.80769527]] / reward: [1071.7117]\n",
            "action: [[0.         0.62735355]] / reward: [-194.85349]\n",
            "action: [[0. 1.]] / reward: [584.5605]\n",
            "action: [[0.        0.5720752]] / reward: [682.00464]\n",
            "action: [[1.7339889 0.       ]] / reward: [1753.7046]\n",
            "action: [[0.1851837 0.3727023]] / reward: [-2045.9907]\n",
            "action: [[0. 0.]] / reward: [-194.85349]\n",
            "Reached the end of the data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# TEST ENVIRONMENT\n",
        "\n",
        "class StockTradingTestEnv(StockTradingEnv):\n",
        "    def __init__(self, df, pct_df, initial_balance=INITIAL_BALANCE):\n",
        "        super().__init__(df, pct_df)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.balance = self.initial_balance\n",
        "        self.train_cnt_epoch=len(self.df.loc[:, 'Close'].values) - 2-6\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        action_type = action[0]\n",
        "        amount = action[1]\n",
        "\n",
        "        close_price = self.df.loc[self.current_step, 'Close']\n",
        "        next_day_close_price=self.df.loc[self.current_step+1, 'Close']\n",
        "\n",
        "        shares_bought = 0\n",
        "        shares_sold = 0\n",
        "        asset_value_before_action = self.balance + self.shares_held * close_price\n",
        "\n",
        "        if action_type < 1:\n",
        "            # Hold\n",
        "            pass\n",
        "        elif action_type < 2:\n",
        "            # Buy\n",
        "            total_possible = int(self.balance / close_price)\n",
        "            shares_bought = int(total_possible * amount)\n",
        "            total_cost = shares_bought * close_price\n",
        "            self.balance -= total_cost\n",
        "            self.shares_held += shares_bought\n",
        "        elif action_type < 3:\n",
        "            # Sell\n",
        "            shares_sold = int(self.shares_held * amount)\n",
        "            self.balance += shares_sold * close_price\n",
        "            self.shares_held -= shares_sold\n",
        "\n",
        "        if self.current_step >= len(self.df.loc[:, 'Close'].values) - 6:\n",
        "            self.current_step = 6\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        asset_value_after_action = self.balance + self.shares_held * next_day_close_price\n",
        "        reward = asset_value_after_action - asset_value_before_action\n",
        "\n",
        "\n",
        "        if self.current_step >= self.train_cnt_epoch:\n",
        "          done = True\n",
        "        else:\n",
        "          done = False\n",
        "\n",
        "        return obs, reward, done, done, {}\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# TEST\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Load the saved model\n",
        "model = PPO.load(MODEL_NAME)\n",
        "\n",
        "# Load the new dataset\n",
        "df_ = yf.download(TICKER_TEST, start=START, end=END)\n",
        "df_ = df_.sort_values('Date')\n",
        "df_ = df_.drop(columns='Adj Close')\n",
        "df_ = df_.reset_index(drop=True)\n",
        "\n",
        "# Create a new percentage change dataframe\n",
        "pct_df_ = df_.copy()\n",
        "\n",
        "for feature in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "    pct_df_[feature] = pct_df_[feature].pct_change()\n",
        "\n",
        "# Adjust the environment to use the new data and the final balance from the training\n",
        "final_training_balance = 100_000\n",
        "env = DummyVecEnv([lambda: StockTradingTestEnv(df_, pct_df_, initial_balance=final_training_balance)])\n",
        "\n",
        "# Set the initial state of the environment\n",
        "initial_state = env.reset()\n",
        "done = False\n",
        "\n",
        "# This list will hold the value of the portfolio at each step\n",
        "portfolio_values = []\n",
        "\n",
        "while not done:\n",
        "    # Get the action from the model\n",
        "    action, _ = model.predict(initial_state)\n",
        "\n",
        "    # Take a step in the environment and get the new state and reward\n",
        "    initial_state, reward, done, info = env.step(action)\n",
        "    print(f'action: {action} / reward: {reward}')\n",
        "    # The current value of the portfolio is the initial balance plus the value of the shares held\n",
        "\n",
        "    if not done:\n",
        "        portfolio_value = env.envs[0].balance + (env.envs[0].shares_held * env.envs[0].df.loc[env.envs[0].current_step, 'Close'])\n",
        "        # print('balance', env.envs[0].balance)\n",
        "        # print('shares_held', env.envs[0].shares_held)\n",
        "        # print('portfolio_value', portfolio_value)\n",
        "        # # Add the portfolio value to the list\n",
        "        portfolio_values.append(portfolio_value)\n",
        "        # print('portfolio_values', portfolio_values)\n",
        "        # print('current_step', env.envs[0].current_step)\n",
        "    else:\n",
        "        print(\"Reached the end of the data.\")\n",
        "\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(portfolio_values)\n",
        "plt.title(f'Portfolio Value {TICKER_TEST} Over Time')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Value')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T8YA2I0fZUgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}