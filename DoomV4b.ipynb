{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8TbHx3irveNsLNBgQs5H7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccasanoval/RLtests/blob/master/DoomV4b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DoomV4b\n",
        "\n",
        "RL  = Stable Baseline 3 : PPO\n",
        "\n",
        "ENV = Gymnasium + VizDoom\n",
        "\n",
        "URL = https://github.com/AKapich/Reinforcement_Learning_Doom\n",
        "\n",
        "URL = https://github.com/AKapich/Reinforcement_Learning_Doom/blob/main/MyWayHome/my_way_home_env.py\n",
        "\n",
        "URL = https://stable-baselines3.readthedocs.io/en/master/"
      ],
      "metadata": {
        "id": "f1PChgxjcgnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vizdoom\n",
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6H6OfSkdOZT",
        "outputId": "e275468d-7106-404c-b4a5-1b1d147ad333"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vizdoom in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (0.29.1)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.3.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.5.82)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U6fVbqDKccsL"
      },
      "outputs": [],
      "source": [
        "############### GYM ENV == VIZ DOOM ###########################################\n",
        "from vizdoom import DoomGame, GameVariable\n",
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Discrete, Box\n",
        "import cv2\n",
        "\n",
        "class MyWayHomeGym(Env):\n",
        "    def __init__(self, scenario, render=True, number_of_actions=3):\n",
        "        self.game = DoomGame()\n",
        "        self.game.load_config(f\"{scenario}.cfg\")\n",
        "\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_X)\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_Y)\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_Z)\n",
        "\n",
        "        self.game.set_window_visible(render)\n",
        "        self.game.init()\n",
        "\n",
        "        self.pos = None\n",
        "        self.pos_history_length = 200\n",
        "        self.position_history = [None] * self.pos_history_length\n",
        "        self.i = 0\n",
        "\n",
        "        self.observation_space = Box(\n",
        "            low=0, high=255, shape=(100, 160, 1), dtype=np.uint8\n",
        "        )\n",
        "        self.number_of_actions = number_of_actions\n",
        "        self.action_space = Discrete(number_of_actions)\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = np.identity(self.number_of_actions)\n",
        "        reward = 100*self.game.make_action(actions[action], tics = 5)\n",
        "\n",
        "        if self.game.get_state():\n",
        "            _, pos_x, pos_y, pos_z = self.game.get_state().game_variables\n",
        "            pos = np.array([pos_x, pos_y, pos_z])\n",
        "\n",
        "            cur_index = self.i % self.pos_history_length\n",
        "            self.i += 1\n",
        "            self.position_history[cur_index] = pos\n",
        "\n",
        "            prev_pos = self.position_history[self.pos_history_length - cur_index - 1]\n",
        "\n",
        "            same_place_penalty = None\n",
        "            if np.array_equal(self.position_history[cur_index], prev_pos):\n",
        "                same_place_penalty = -1\n",
        "            else:\n",
        "                same_place_penalty = (\n",
        "                    -0.5\n",
        "                    / np.sqrt(\n",
        "                        np.sum((self.position_history[cur_index] - prev_pos) ** 2)\n",
        "                    )\n",
        "                    if prev_pos is not None\n",
        "                    else 0\n",
        "                )\n",
        "\n",
        "            same_place_penalty = max(-1, same_place_penalty)\n",
        "            reward += same_place_penalty\n",
        "\n",
        "        if self.game.get_state():\n",
        "            state = self.game.get_state().screen_buffer\n",
        "            state = self.grayscale(state)\n",
        "        else:\n",
        "            state = np.zeros(self.observation_space.shape)\n",
        "\n",
        "        info = 0\n",
        "        info = {\"info\": info}\n",
        "        terminated = self.game.is_episode_finished()\n",
        "\n",
        "        truncated = (\n",
        "            self.game.is_player_dead()\n",
        "            or self.game.is_player_dead()\n",
        "            or self.game.is_player_dead()\n",
        "        )\n",
        "\n",
        "        return state, reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, seed=0):\n",
        "        self.game.new_episode()\n",
        "        state = self.game.get_state().screen_buffer\n",
        "\n",
        "        if self.game.get_state():\n",
        "            info = self.game.get_state().game_variables[0]  # ammo\n",
        "        else:\n",
        "            info = 0\n",
        "\n",
        "        return (self.grayscale(state), {\"ammo\": info})\n",
        "\n",
        "    def grayscale(self, observation):\n",
        "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
        "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
        "        state = np.reshape(resize, (100, 160, 1))\n",
        "        return state\n",
        "\n",
        "    def close(self):\n",
        "        self.game.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##################### SB3 : CALLBACK ##########################################\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq, verbose=1, name=\"?\"):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.name = name\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = '{}_{}'.format(self.name, self.n_calls)\n",
        "            self.model.save(model_path)\n",
        "        return True\n",
        "\n"
      ],
      "metadata": {
        "id": "lEFdol6dc2rj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "modelType = \"PPO\"     # @param {type:\"string\"}\n",
        "modelName = \"DoomHome\"+modelType # @param {type:\"string\"}\n",
        "modelNew = True       # @param {type:\"boolean\"}\n",
        "modelTrain = True     # @param {type:\"boolean\"}\n",
        "\n",
        "print(modelName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ0IVRQndj1z",
        "outputId": "12a0f501-abd1-4733-a9cb-e72c65b59f11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoomHomePPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###################### TRAIN == SB3 ###########################################\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "callback = TrainAndLoggingCallback(check_freq=10000, name=modelName)\n",
        "env = MyWayHomeGym(render=False, scenario=\"my_way_home\")\n",
        "\n",
        "if modelNew:\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        seed=0,\n",
        "        learning_rate=0.0001,\n",
        "        n_steps=2048,\n",
        "    )\n",
        "else:\n",
        "    model = PPO.load(modelName, env=env)\n",
        "\n",
        "# TRAIN\n",
        "if modelTrain:\n",
        "    model.learn(\n",
        "        total_timesteps=200000,\n",
        "        callback=callback,\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNwOTGgIc7UM",
        "outputId": "f9c4cd14-4546-4b52-e55f-c4e5b5fd9095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 525      |\n",
            "|    ep_rew_mean     | -70.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 96       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 525          |\n",
            "|    ep_rew_mean          | -78.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 28           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 141          |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017578574 |\n",
            "|    clip_fraction        | 0.00239      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | -0.0113      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.17         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    value_loss           | 12.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 525          |\n",
            "|    ep_rew_mean          | -69.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 23           |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 256          |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071613602 |\n",
            "|    clip_fraction        | 0.105        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.189        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.31         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 8.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 525          |\n",
            "|    ep_rew_mean          | -60.4        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 22           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 370          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059573073 |\n",
            "|    clip_fraction        | 0.0615       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.172        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 6.02         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00336     |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 511          |\n",
            "|    ep_rew_mean          | -56.4        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 21           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 483          |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066674277 |\n",
            "|    clip_fraction        | 0.0668       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.0188       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.65         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00652     |\n",
            "|    value_loss           | 5.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 493          |\n",
            "|    ep_rew_mean          | -64          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 20           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 596          |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056372806 |\n",
            "|    clip_fraction        | 0.0574       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | -0.0294      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.92         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00429     |\n",
            "|    value_loss           | 7.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 484          |\n",
            "|    ep_rew_mean          | -62.5        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 20           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 708          |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071260342 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | -0.0608      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.33         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000165    |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 489         |\n",
            "|    ep_rew_mean          | -63.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 19          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 821         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012359964 |\n",
            "|    clip_fraction        | 0.0987      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.127       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.99        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00018    |\n",
            "|    value_loss           | 8.54        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 493         |\n",
            "|    ep_rew_mean          | -63.8       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 19          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 932         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009533219 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.983      |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.93        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00762    |\n",
            "|    value_loss           | 10.9        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################### TEST == SB3 ########################################\n",
        "model = PPO.load(modelName, env=env)\n",
        "env = env = MyWayHomeGym(render=True, scenario=\"my_way_home\")\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "env.close()\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f}\")\n",
        "print(f\"std_reward:{std_reward:.2f}\")\n"
      ],
      "metadata": {
        "id": "ka09sdlAdAeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZGSRQLCdAlb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}