{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccasanoval/RLtests/blob/master/DoomV4b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1PChgxjcgnW"
      },
      "source": [
        "#DoomV4b\n",
        "\n",
        "RL  = Stable Baseline 3 : PPO\n",
        "\n",
        "ENV = Gymnasium + VizDoom\n",
        "\n",
        "URL = https://github.com/AKapich/Reinforcement_Learning_Doom\n",
        "\n",
        "URL = https://github.com/AKapich/Reinforcement_Learning_Doom/blob/main/MyWayHome/my_way_home_env.py\n",
        "\n",
        "URL = https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "\n",
        "###.\n",
        "### ALSO TEST : RLlib\n",
        "\n",
        "###.\n",
        "###Â ALSTO TRY: callbacks\n",
        "\n",
        "https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/4_callbacks_hyperparameter_tuning.ipynb#scrollTo=adsKMvDkRUn0\n",
        "\n",
        "###.\n",
        "### ALSO READ: Algorithm Distilation + In Context RL\n",
        "\n",
        "https://www.youtube.com/watch?v=BkWLCrLapQo\n",
        "\n",
        "https://github.com/licong-lin/in-context-rl\n",
        "    \n",
        "###.\n",
        "### ALSO READ:\n",
        "\n",
        "Automatic hyperparameter optimization\n",
        "\n",
        "To optimize the parameters of C, we chose the Covariance-Matrix Adaptation Evolution Strategy (CMA-ES)\n",
        "\n",
        "###.\n",
        "Do androids dream of electric sheep?\n",
        "\n",
        "https://worldmodels.github.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6H6OfSkdOZT",
        "outputId": "a78bf85a-4e95-4a7f-a9f6-a3021520a01d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vizdoom in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (0.29.1)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.3.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.5.82)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install vizdoom\n",
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U6fVbqDKccsL"
      },
      "outputs": [],
      "source": [
        "############### GYM ENV == VIZ DOOM ###########################################\n",
        "from vizdoom import DoomGame, GameVariable\n",
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Discrete, Box\n",
        "import cv2\n",
        "\n",
        "class MyWayHomeGym(Env):\n",
        "    def __init__(self, scenario, render=True, number_of_actions=3):\n",
        "        self.game = DoomGame()\n",
        "        self.game.load_config(f\"{scenario}.cfg\")\n",
        "\n",
        "        # self.game.set_mode(Mode.SPECTATOR)  # spectator\n",
        "\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_X)\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_Y)\n",
        "        self.game.add_available_game_variable(GameVariable.POSITION_Z)\n",
        "\n",
        "        self.pos = None\n",
        "\n",
        "        self.game.set_window_visible(render)\n",
        "        self.game.init()\n",
        "\n",
        "        self.observation_space = Box(\n",
        "            low=0, high=255, shape=(100, 160, 1), dtype=np.uint8\n",
        "        )\n",
        "        self.number_of_actions = number_of_actions\n",
        "        self.action_space = Discrete(number_of_actions)\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = np.identity(self.number_of_actions)\n",
        "        reward = 10 * self.game.make_action(actions[action], tics = 4)\n",
        "\n",
        "        dist = 0\n",
        "        movement_reward = 0\n",
        "\n",
        "        if self.game.get_state():\n",
        "            #_, pos_x, pos_y, pos_z = self.game.get_state().game_variables\n",
        "            #pos = np.array([pos_x, pos_y, pos_z])\n",
        "\n",
        "            # MOVEMENT REWARD\n",
        "            #if self.pos is not None:\n",
        "            #    dist = np.sqrt(np.sum((pos - self.pos) ** 2))\n",
        "            #    movement_reward = dist * 0.005\n",
        "            #self.pos = pos\n",
        "\n",
        "            state = self.game.get_state().screen_buffer\n",
        "            state = self.grayscale(state)\n",
        "            info = self.game.get_state().game_variables[0]  # ammo\n",
        "        else:\n",
        "            state = np.zeros(self.observation_space.shape)\n",
        "            info = 0\n",
        "\n",
        "        info = {\"info\": info}\n",
        "        terminated = self.game.is_episode_finished()\n",
        "\n",
        "        truncated = (\n",
        "            self.game.is_player_dead()\n",
        "            or self.game.is_player_dead()\n",
        "            or self.game.is_player_dead()\n",
        "        )\n",
        "\n",
        "        #print(f\"------------- reward = {reward} dist = {dist} movement_reward = {movement_reward} \")\n",
        "        #reward += movement_reward\n",
        "        return state, reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, seed=0):\n",
        "        self.game.new_episode()\n",
        "        state = self.game.get_state().screen_buffer\n",
        "\n",
        "        if self.game.get_state():\n",
        "            info = self.game.get_state().game_variables[0]  # ammo\n",
        "        else:\n",
        "            info = 0\n",
        "\n",
        "        return (self.grayscale(state), {\"ammo\": info})\n",
        "\n",
        "    def grayscale(self, observation):\n",
        "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
        "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
        "        state = np.reshape(resize, (100, 160, 1))\n",
        "        return state\n",
        "\n",
        "    def close(self):\n",
        "        self.game.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lEFdol6dc2rj"
      },
      "outputs": [],
      "source": [
        "\n",
        "##################### SB3 : CALLBACK ##########################################\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq, verbose=1, name=\"?\"):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.name = name\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = '{}_{}'.format(self.name, self.n_calls)\n",
        "            self.model.save(model_path)\n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ0IVRQndj1z",
        "outputId": "6fcc3e3e-d98a-4d96-da82-4d2498fb2baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoomHomePPO\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "modelType = \"PPO\"     # @param {type:\"string\"}\n",
        "modelName = \"DoomHome\"+modelType # @param {type:\"string\"}\n",
        "modelNew = True       # @param {type:\"boolean\"}\n",
        "modelTrain = True     # @param {type:\"boolean\"}\n",
        "\n",
        "print(modelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNwOTGgIc7UM",
        "outputId": "cb2307b5-fff3-491e-907a-2022a3cd73d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 525      |\n",
            "|    ep_rew_mean     | -2.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 108      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | -0.617      |\n",
            "| time/                   |             |\n",
            "|    fps                  | 33          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 121         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009081036 |\n",
            "|    clip_fraction        | 0.0805      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.0506      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.0416     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 0.00982     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 486         |\n",
            "|    ep_rew_mean          | -1.11       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 27          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005160924 |\n",
            "|    clip_fraction        | 0.0384      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.00318     |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.00032     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    value_loss           | 0.201       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 496         |\n",
            "|    ep_rew_mean          | -1.36       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 25          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 326         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009777723 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | -2.63       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.0299     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0227     |\n",
            "|    value_loss           | 0.096       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 502         |\n",
            "|    ep_rew_mean          | -1.51       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 23          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 429         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013661584 |\n",
            "|    clip_fraction        | 0.086       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | -0.00764    |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.0577     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0348     |\n",
            "|    value_loss           | 0.00981     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 506         |\n",
            "|    ep_rew_mean          | -1.61       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 23          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 531         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027081802 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | -0.0992     |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.0904     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0535     |\n",
            "|    value_loss           | 0.00468     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 502        |\n",
            "|    ep_rew_mean          | -1.29      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 22         |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 632        |\n",
            "|    total_timesteps      | 14336      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02598319 |\n",
            "|    clip_fraction        | 0.249      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.01      |\n",
            "|    explained_variance   | 0.0428     |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | -0.077     |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.049     |\n",
            "|    value_loss           | 0.0042     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 495         |\n",
            "|    ep_rew_mean          | -1.07       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 22          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 739         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023890302 |\n",
            "|    clip_fraction        | 0.194       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.00713     |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.00764    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0311     |\n",
            "|    value_loss           | 0.188       |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "###################### TRAIN == SB3 ###########################################\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "callback = TrainAndLoggingCallback(check_freq=10000, name=modelName)\n",
        "env = MyWayHomeGym(render=False, scenario=\"my_way_home\")\n",
        "\n",
        "if modelNew:\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        seed=0,\n",
        "        learning_rate=0.0001,\n",
        "        n_steps=2048,\n",
        "    )\n",
        "else:\n",
        "    model = PPO.load(modelName, env=env)\n",
        "\n",
        "# TRAIN\n",
        "if modelTrain:\n",
        "    model.learn(\n",
        "        total_timesteps=200000,\n",
        "        callback=callback,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka09sdlAdAeN"
      },
      "outputs": [],
      "source": [
        "###################### TEST == SB3 ########################################\n",
        "model = PPO.load(modelName, env=env)\n",
        "env = env = MyWayHomeGym(render=True, scenario=\"my_way_home\")\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "env.close()\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f}\")\n",
        "print(f\"std_reward:{std_reward:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZGSRQLCdAlb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyNvcYCXlAq8syk+IA67UZwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}